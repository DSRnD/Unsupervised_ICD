{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:37.369175Z",
     "iopub.status.busy": "2021-05-26T08:34:37.368412Z",
     "iopub.status.idle": "2021-05-26T08:34:37.383780Z",
     "shell.execute_reply": "2021-05-26T08:34:37.384518Z"
    },
    "papermill": {
     "duration": 0.051057,
     "end_time": "2021-05-26T08:34:37.384703",
     "exception": false,
     "start_time": "2021-05-26T08:34:37.333646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mimicdata/validation_full.csv\n",
      "/kaggle/input/mimicdata/test_full.csv\n",
      "/kaggle/input/mimicdata/vocab.csv\n",
      "/kaggle/input/mimicdata/train_full.csv\n",
      "/kaggle/input/mimicdata/ICD_desc_with_freq.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/mimicdata'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:37.446316Z",
     "iopub.status.busy": "2021-05-26T08:34:37.445228Z",
     "iopub.status.idle": "2021-05-26T08:34:39.192573Z",
     "shell.execute_reply": "2021-05-26T08:34:39.191180Z"
    },
    "papermill": {
     "duration": 1.777883,
     "end_time": "2021-05-26T08:34:39.192800",
     "exception": false,
     "start_time": "2021-05-26T08:34:37.414917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12722, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "te = pd.read_csv('/kaggle/input/mimicdata/test_full.csv')\n",
    "te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:39.269400Z",
     "iopub.status.busy": "2021-05-26T08:34:39.268660Z",
     "iopub.status.idle": "2021-05-26T08:34:41.988574Z",
     "shell.execute_reply": "2021-05-26T08:34:41.989239Z"
    },
    "papermill": {
     "duration": 2.762649,
     "end_time": "2021-05-26T08:34:41.989407",
     "exception": false,
     "start_time": "2021-05-26T08:34:39.226758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import collections\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from math import floor\n",
    "import random\n",
    "\n",
    "import os.path\n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.052585Z",
     "iopub.status.busy": "2021-05-26T08:34:42.050907Z",
     "iopub.status.idle": "2021-05-26T08:34:42.163641Z",
     "shell.execute_reply": "2021-05-26T08:34:42.163083Z"
    },
    "papermill": {
     "duration": 0.146002,
     "end_time": "2021-05-26T08:34:42.163781",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.017779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_metrics(yhat, y, k=8, yhat_raw=None, calc_auc=True):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            yhat: binary predictions matrix \n",
    "            y: binary ground truth matrix\n",
    "            k: for @k metrics\n",
    "            yhat_raw: prediction scores matrix (floats)\n",
    "        Outputs:\n",
    "            dict holding relevant metrics\n",
    "    \"\"\"\n",
    "    names = [\"acc\", \"prec\", \"rec\", \"f1\"]\n",
    "\n",
    "    #macro\n",
    "    macro = all_macro(yhat, y)\n",
    "\n",
    "    #micro\n",
    "    ymic = y.ravel()\n",
    "    yhatmic = yhat.ravel()\n",
    "    micro = all_micro(yhatmic, ymic)\n",
    "    #print (\"\\nHere is the predicted label and actual label in micro basis\\n\", yhatmic,\"\\n\",ymic,\"\\nShape of yhat and y are \",yhatmic.shape,ymic.shape)\n",
    "\n",
    "    metrics = {names[i] + \"_macro\": macro[i] for i in range(len(macro))}\n",
    "    metrics.update({names[i] + \"_micro\": micro[i] for i in range(len(micro))})\n",
    "\n",
    "    #AUC and @k\n",
    "    if yhat_raw is not None and calc_auc:\n",
    "        #allow k to be passed as int or list\n",
    "        if type(k) != list:\n",
    "            k = [k]\n",
    "        for k_i in k:\n",
    "            rec_at_k = recall_at_k(yhat_raw, y, k_i)\n",
    "            metrics['rec_at_%d' % k_i] = rec_at_k\n",
    "            prec_at_k = precision_at_k(yhat_raw, y, k_i)\n",
    "            metrics['prec_at_%d' % k_i] = prec_at_k\n",
    "            metrics['f1_at_%d' % k_i] = 2*(prec_at_k*rec_at_k)/(prec_at_k+rec_at_k)\n",
    "\n",
    "        roc_auc = auc_metrics(yhat_raw, y, ymic)\n",
    "        metrics.update(roc_auc)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def all_macro(yhat, y):\n",
    "    return macro_accuracy(yhat, y), macro_precision(yhat, y), macro_recall(yhat, y), macro_f1(yhat, y)\n",
    "\n",
    "def all_micro(yhatmic, ymic):\n",
    "    print (\"\\nHere is the specificty result\", micro_specificty(yhatmic, ymic))\n",
    "    return micro_accuracy(yhatmic, ymic), micro_precision(yhatmic, ymic), micro_recall(yhatmic, ymic), micro_f1(yhatmic, ymic)\n",
    "\n",
    "#########################################################################\n",
    "#MACRO METRICS: calculate metric for each label and average across labels\n",
    "#########################################################################\n",
    "\n",
    "def macro_accuracy(yhat, y):\n",
    "    num = intersect_size(yhat, y, 0) / (union_size(yhat, y, 0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "def macro_precision(yhat, y):\n",
    "    num = intersect_size(yhat, y, 0) / (yhat.sum(axis=0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "def macro_recall(yhat, y):\n",
    "    num = intersect_size(yhat, y, 0) / (y.sum(axis=0) + 1e-10)\n",
    "    return np.mean(num)\n",
    "\n",
    "def macro_f1(yhat, y):\n",
    "    prec = macro_precision(yhat, y)\n",
    "    rec = macro_recall(yhat, y)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2*(prec*rec)/(prec+rec)\n",
    "    return f1\n",
    "\n",
    "###################\n",
    "# INSTANCE-AVERAGED\n",
    "###################\n",
    "\n",
    "def inst_precision(yhat, y):\n",
    "    num = intersect_size(yhat, y, 1) / yhat.sum(axis=1)\n",
    "    #correct for divide-by-zeros\n",
    "    num[np.isnan(num)] = 0.\n",
    "    return np.mean(num)\n",
    "\n",
    "def inst_recall(yhat, y):\n",
    "    num = intersect_size(yhat, y, 1) / y.sum(axis=1)\n",
    "    #correct for divide-by-zeros\n",
    "    num[np.isnan(num)] = 0.\n",
    "    return np.mean(num)\n",
    "\n",
    "def inst_f1(yhat, y):\n",
    "    prec = inst_precision(yhat, y)\n",
    "    rec = inst_recall(yhat, y)\n",
    "    f1 = 2*(prec*rec)/(prec+rec)\n",
    "    return f1\n",
    "\n",
    "##############\n",
    "# AT-K\n",
    "##############\n",
    "\n",
    "def recall_at_k(yhat_raw, y, k):\n",
    "    #num true labels in top k predictions / num true labels\n",
    "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
    "    topk = sortd[:,:k]\n",
    "\n",
    "    #get recall at k for each example\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        num_true_in_top_k = y[i,tk].sum()\n",
    "        denom = y[i,:].sum()\n",
    "        vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "    vals = np.array(vals)\n",
    "    vals[np.isnan(vals)] = 0.\n",
    "\n",
    "    return np.mean(vals)\n",
    "\n",
    "def precision_at_k(yhat_raw, y, k):\n",
    "    #num true labels in top k predictions / k\n",
    "    sortd = np.argsort(yhat_raw)[:,::-1]\n",
    "    topk = sortd[:,:k]\n",
    "\n",
    "    #get precision at k for each example\n",
    "    vals = []\n",
    "    for i, tk in enumerate(topk):\n",
    "        if len(tk) > 0:\n",
    "            num_true_in_top_k = y[i,tk].sum()\n",
    "            denom = len(tk)\n",
    "            vals.append(num_true_in_top_k / float(denom))\n",
    "\n",
    "    return np.mean(vals)\n",
    "\n",
    "##########################################################################\n",
    "#MICRO METRICS: treat every prediction as an individual binary prediction\n",
    "##########################################################################\n",
    "\n",
    "def micro_specificty(yhatmic, ymic):\n",
    "    TN  = 2833-(ymic.sum(axis=0))-(yhatmic.sum(axis=0) - intersect_size(yhatmic, ymic, 0))\n",
    "    return TN/(TN + (yhatmic.sum(axis=0) - intersect_size(yhatmic, ymic, 0)))\n",
    "\n",
    "def micro_accuracy(yhatmic, ymic):\n",
    "    return intersect_size(yhatmic, ymic, 0) / union_size(yhatmic, ymic, 0)\n",
    "\n",
    "def micro_precision(yhatmic, ymic):\n",
    "    return intersect_size(yhatmic, ymic, 0) / yhatmic.sum(axis=0)\n",
    "\n",
    "def micro_recall(yhatmic, ymic):\n",
    "    return intersect_size(yhatmic, ymic, 0) / ymic.sum(axis=0)\n",
    "\n",
    "def micro_f1(yhatmic, ymic):\n",
    "    prec = micro_precision(yhatmic, ymic)\n",
    "    rec = micro_recall(yhatmic, ymic)\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.\n",
    "    else:\n",
    "        f1 = 2*(prec*rec)/(prec+rec)\n",
    "    return f1\n",
    "\n",
    "def auc_metrics(yhat_raw, y, ymic):\n",
    "    if yhat_raw.shape[0] <= 1:\n",
    "        return\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    #get AUC for each label individually\n",
    "    relevant_labels = []\n",
    "    auc_labels = {}\n",
    "    for i in range(y.shape[1]):\n",
    "        #only if there are true positives for this label\n",
    "        if y[:,i].sum() > 0:\n",
    "            fpr[i], tpr[i], _ = roc_curve(y[:,i], yhat_raw[:,i])\n",
    "            if len(fpr[i]) > 1 and len(tpr[i]) > 1:\n",
    "                auc_score = auc(fpr[i], tpr[i])\n",
    "                if not np.isnan(auc_score): \n",
    "                    auc_labels[\"auc_%d\" % i] = auc_score\n",
    "                    relevant_labels.append(i)\n",
    "\n",
    "    #macro-AUC: just average the auc scores\n",
    "    aucs = []\n",
    "    for i in relevant_labels:\n",
    "        aucs.append(auc_labels['auc_%d' % i])\n",
    "    roc_auc['auc_macro'] = np.mean(aucs)\n",
    "\n",
    "    #micro-AUC: just look at each individual prediction\n",
    "    yhatmic = yhat_raw.ravel()\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ymic, yhatmic) \n",
    "    roc_auc[\"auc_micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "########################\n",
    "# METRICS BY CODE TYPE\n",
    "########################\n",
    "\n",
    "def results_by_type(Y, mdir, version='mimic3'):\n",
    "    d2ind = {}\n",
    "    p2ind = {}\n",
    "\n",
    "    #get predictions for diagnoses and procedures\n",
    "    diag_preds = defaultdict(lambda: set([]))\n",
    "    proc_preds = defaultdict(lambda: set([]))\n",
    "    preds = defaultdict(lambda: set())\n",
    "    with open('%s/preds_test.psv' % mdir, 'r') as f:\n",
    "        r = csv.reader(f, delimiter='|')\n",
    "        for row in r:\n",
    "            if len(row) > 1:\n",
    "                for code in row[1:]:\n",
    "                    preds[row[0]].add(code)\n",
    "                    if code != '':\n",
    "                        try:\n",
    "                            pos = code.index('.')\n",
    "                            if pos == 3 or (code[0] == 'E' and pos == 4):\n",
    "                                if code not in d2ind:\n",
    "                                    d2ind[code] = len(d2ind)\n",
    "                                diag_preds[row[0]].add(code)\n",
    "                            elif pos == 2:\n",
    "                                if code not in p2ind:\n",
    "                                    p2ind[code] = len(p2ind)\n",
    "                                proc_preds[row[0]].add(code)\n",
    "                        except:\n",
    "                            if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
    "                                if code not in d2ind:\n",
    "                                    d2ind[code] = len(d2ind)\n",
    "                                diag_preds[row[0]].add(code)\n",
    "    #get ground truth for diagnoses and procedures\n",
    "    diag_golds = defaultdict(lambda: set([]))\n",
    "    proc_golds = defaultdict(lambda: set([]))\n",
    "    golds = defaultdict(lambda: set())\n",
    "    test_file = '%s/test_%s.csv' % (MIMIC_3_DIR, str(Y)) if version == 'mimic3' else '%s/test.csv' % MIMIC_2_DIR\n",
    "    with open(test_file, 'r') as f:\n",
    "        r = csv.reader(f)\n",
    "        #header\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            codes = set([c for c in row[3].split(';')])\n",
    "            for code in codes:\n",
    "                golds[row[1]].add(code)\n",
    "                try:\n",
    "                    pos = code.index('.')\n",
    "                    if pos == 3:\n",
    "                        if code not in d2ind:\n",
    "                            d2ind[code] = len(d2ind)\n",
    "                        diag_golds[row[1]].add(code)\n",
    "                    elif pos == 2:\n",
    "                        if code not in p2ind:\n",
    "                            p2ind[code] = len(p2ind)\n",
    "                        proc_golds[row[1]].add(code)\n",
    "                except:\n",
    "                    if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
    "                        if code not in d2ind:\n",
    "                            d2ind[code] = len(d2ind)\n",
    "                        diag_golds[row[1]].add(code)\n",
    "\n",
    "    hadm_ids = sorted(set(diag_golds.keys()).intersection(set(diag_preds.keys())))\n",
    "\n",
    "    ind2d = {i:d for d,i in d2ind.items()}\n",
    "    ind2p = {i:p for p,i in p2ind.items()}\n",
    "    type_dicts = (ind2d, ind2p)\n",
    "    return diag_preds, diag_golds, proc_preds, proc_golds, golds, preds, hadm_ids, type_dicts\n",
    "\n",
    "\n",
    "def diag_f1(diag_preds, diag_golds, ind2d, hadm_ids):\n",
    "    num_labels = len(ind2d)\n",
    "    yhat_diag = np.zeros((len(hadm_ids), num_labels))\n",
    "    y_diag = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_diag_inds = [1 if ind2d[j] in diag_preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_diag_inds = [1 if ind2d[j] in diag_golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_diag[i] = yhat_diag_inds\n",
    "        y_diag[i] = gold_diag_inds\n",
    "    return micro_f1(yhat_diag.ravel(), y_diag.ravel())\n",
    "\n",
    "def proc_f1(proc_preds, proc_golds, ind2p, hadm_ids):\n",
    "    num_labels = len(ind2p)\n",
    "    yhat_proc = np.zeros((len(hadm_ids), num_labels))\n",
    "    y_proc = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_proc_inds = [1 if ind2p[j] in proc_preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_proc_inds = [1 if ind2p[j] in proc_golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_proc[i] = yhat_proc_inds\n",
    "        y_proc[i] = gold_proc_inds\n",
    "    return micro_f1(yhat_proc.ravel(), y_proc.ravel())\n",
    "\n",
    "def metrics_from_dicts(preds, golds, mdir, ind2c):\n",
    "    with open('%s/pred_100_scores_test.json' % mdir, 'r') as f:\n",
    "        scors = json.load(f)\n",
    "\n",
    "    hadm_ids = sorted(set(golds.keys()).intersection(set(preds.keys())))\n",
    "    num_labels = len(ind2c)\n",
    "    yhat = np.zeros((len(hadm_ids), num_labels))\n",
    "    yhat_raw = np.zeros((len(hadm_ids), num_labels))\n",
    "    y = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_inds = [1 if ind2c[j] in preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_raw_inds = [scors[hadm_id][ind2c[j]] if ind2c[j] in scors[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_inds = [1 if ind2c[j] in golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat[i] = yhat_inds\n",
    "        yhat_raw[i] = yhat_raw_inds\n",
    "        y[i] = gold_inds\n",
    "    return yhat, yhat_raw, y, all_metrics(yhat, y, yhat_raw=yhat_raw, calc_auc=False)\n",
    "\n",
    "\n",
    "def union_size(yhat, y, axis):\n",
    "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
    "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def intersect_size(yhat, y, axis):\n",
    "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
    "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print()\n",
    "    if \"auc_macro\" in metrics.keys():\n",
    "        print(\"[MACRO] accuracy, precision, recall, f-measure, AUC\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"], metrics[\"auc_macro\"]))\n",
    "    else:\n",
    "        print(\"[MACRO] accuracy, precision, recall, f-measure\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"]))\n",
    "\n",
    "    if \"auc_micro\" in metrics.keys():\n",
    "        print(\"[MICRO] accuracy, precision, recall, f-measure, AUC\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"], metrics[\"auc_micro\"]))\n",
    "    else:\n",
    "        print(\"[MICRO] accuracy, precision, recall, f-measure\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"]))\n",
    "    for metric, val in metrics.items():\n",
    "        if metric.find(\"rec_at\") != -1:\n",
    "            print(\"%s: %.4f\" % (metric, val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.238347Z",
     "iopub.status.busy": "2021-05-26T08:34:42.233141Z",
     "iopub.status.idle": "2021-05-26T08:34:42.513189Z",
     "shell.execute_reply": "2021-05-26T08:34:42.512597Z"
    },
    "papermill": {
     "duration": 0.319529,
     "end_time": "2021-05-26T08:34:42.513327",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.193798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def results_by_type(Y, mdir, version='mimic3'):\n",
    "    d2ind = {}\n",
    "    p2ind = {}\n",
    "\n",
    "    #get predictions for diagnoses and procedures\n",
    "    diag_preds = defaultdict(lambda: set([]))\n",
    "    proc_preds = defaultdict(lambda: set([]))\n",
    "    preds = defaultdict(lambda: set())\n",
    "    with open('%s/preds_test.psv' % mdir, 'r') as f:\n",
    "        r = csv.reader(f, delimiter='|')\n",
    "        for row in r:\n",
    "            if len(row) > 1:\n",
    "                for code in row[1:]:\n",
    "                    preds[row[0]].add(code)\n",
    "                    if code != '':\n",
    "                        try:\n",
    "                            pos = code.index('.')\n",
    "                            if pos == 3 or (code[0] == 'E' and pos == 4):\n",
    "                                if code not in d2ind:\n",
    "                                    d2ind[code] = len(d2ind)\n",
    "                                diag_preds[row[0]].add(code)\n",
    "                            elif pos == 2:\n",
    "                                if code not in p2ind:\n",
    "                                    p2ind[code] = len(p2ind)\n",
    "                                proc_preds[row[0]].add(code)\n",
    "                        except:\n",
    "                            if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
    "                                if code not in d2ind:\n",
    "                                    d2ind[code] = len(d2ind)\n",
    "                                diag_preds[row[0]].add(code)\n",
    "    #get ground truth for diagnoses and procedures\n",
    "    diag_golds = defaultdict(lambda: set([]))\n",
    "    proc_golds = defaultdict(lambda: set([]))\n",
    "    golds = defaultdict(lambda: set())\n",
    "    test_file = '%s/test_%s.csv' % (MIMIC_3_DIR, str(Y)) if version == 'mimic3' else '%s/test.csv' % MIMIC_2_DIR\n",
    "    with open(test_file, 'r') as f:\n",
    "        r = csv.reader(f)\n",
    "        #header\n",
    "        next(r)\n",
    "        for row in r:\n",
    "            codes = set([c for c in row[3].split(';')])\n",
    "            for code in codes:\n",
    "                golds[row[1]].add(code)\n",
    "                try:\n",
    "                    pos = code.index('.')\n",
    "                    if pos == 3:\n",
    "                        if code not in d2ind:\n",
    "                            d2ind[code] = len(d2ind)\n",
    "                        diag_golds[row[1]].add(code)\n",
    "                    elif pos == 2:\n",
    "                        if code not in p2ind:\n",
    "                            p2ind[code] = len(p2ind)\n",
    "                        proc_golds[row[1]].add(code)\n",
    "                except:\n",
    "                    if len(code) == 3 or (code[0] == 'E' and len(code) == 4):\n",
    "                        if code not in d2ind:\n",
    "                            d2ind[code] = len(d2ind)\n",
    "                        diag_golds[row[1]].add(code)\n",
    "\n",
    "    hadm_ids = sorted(set(diag_golds.keys()).intersection(set(diag_preds.keys())))\n",
    "\n",
    "    ind2d = {i:d for d,i in d2ind.items()}\n",
    "    ind2p = {i:p for p,i in p2ind.items()}\n",
    "    type_dicts = (ind2d, ind2p)\n",
    "    return diag_preds, diag_golds, proc_preds, proc_golds, golds, preds, hadm_ids, type_dicts\n",
    "\n",
    "\n",
    "def diag_f1(diag_preds, diag_golds, ind2d, hadm_ids):\n",
    "    num_labels = len(ind2d)\n",
    "    yhat_diag = np.zeros((len(hadm_ids), num_labels))\n",
    "    y_diag = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_diag_inds = [1 if ind2d[j] in diag_preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_diag_inds = [1 if ind2d[j] in diag_golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_diag[i] = yhat_diag_inds\n",
    "        y_diag[i] = gold_diag_inds\n",
    "    return micro_f1(yhat_diag.ravel(), y_diag.ravel())\n",
    "\n",
    "def proc_f1(proc_preds, proc_golds, ind2p, hadm_ids):\n",
    "    num_labels = len(ind2p)\n",
    "    yhat_proc = np.zeros((len(hadm_ids), num_labels))\n",
    "    y_proc = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_proc_inds = [1 if ind2p[j] in proc_preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_proc_inds = [1 if ind2p[j] in proc_golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_proc[i] = yhat_proc_inds\n",
    "        y_proc[i] = gold_proc_inds\n",
    "    return micro_f1(yhat_proc.ravel(), y_proc.ravel())\n",
    "\n",
    "def metrics_from_dicts(preds, golds, mdir, ind2c):\n",
    "    with open('%s/pred_100_scores_test.json' % mdir, 'r') as f:\n",
    "        scors = json.load(f)\n",
    "\n",
    "    hadm_ids = sorted(set(golds.keys()).intersection(set(preds.keys())))\n",
    "    num_labels = len(ind2c)\n",
    "    yhat = np.zeros((len(hadm_ids), num_labels))\n",
    "    yhat_raw = np.zeros((len(hadm_ids), num_labels))\n",
    "    y = np.zeros((len(hadm_ids), num_labels))\n",
    "    for i,hadm_id in tqdm(enumerate(hadm_ids)):\n",
    "        yhat_inds = [1 if ind2c[j] in preds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat_raw_inds = [scors[hadm_id][ind2c[j]] if ind2c[j] in scors[hadm_id] else 0 for j in range(num_labels)]\n",
    "        gold_inds = [1 if ind2c[j] in golds[hadm_id] else 0 for j in range(num_labels)]\n",
    "        yhat[i] = yhat_inds\n",
    "        yhat_raw[i] = yhat_raw_inds\n",
    "        y[i] = gold_inds\n",
    "    return yhat, yhat_raw, y, all_metrics(yhat, y, yhat_raw=yhat_raw, calc_auc=False)\n",
    "\n",
    "\n",
    "def union_size(yhat, y, axis):\n",
    "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
    "    return np.logical_or(yhat, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def intersect_size(yhat, y, axis):\n",
    "    #axis=0 for label-level union (macro). axis=1 for instance-level\n",
    "    return np.logical_and(yhat, y).sum(axis=axis).astype(float)\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    print()\n",
    "    if \"auc_macro\" in metrics.keys():\n",
    "        print(\"[MACRO] accuracy, precision, recall, f-measure, AUC\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"], metrics[\"auc_macro\"]))\n",
    "    else:\n",
    "        print(\"[MACRO] accuracy, precision, recall, f-measure\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_macro\"], metrics[\"prec_macro\"], metrics[\"rec_macro\"], metrics[\"f1_macro\"]))\n",
    "\n",
    "    if \"auc_micro\" in metrics.keys():\n",
    "        print(\"[MICRO] accuracy, precision, recall, f-measure, AUC\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"], metrics[\"auc_micro\"]))\n",
    "    else:\n",
    "        print(\"[MICRO] accuracy, precision, recall, f-measure\")\n",
    "        print(\"%.4f, %.4f, %.4f, %.4f\" % (metrics[\"acc_micro\"], metrics[\"prec_micro\"], metrics[\"rec_micro\"], metrics[\"f1_micro\"]))\n",
    "    for metric, val in metrics.items():\n",
    "        if metric.find(\"rec_at\") != -1:\n",
    "            print(\"%s: %.4f\" % (metric, val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.578773Z",
     "iopub.status.busy": "2021-05-26T08:34:42.578105Z",
     "iopub.status.idle": "2021-05-26T08:34:42.581304Z",
     "shell.execute_reply": "2021-05-26T08:34:42.580635Z"
    },
    "papermill": {
     "duration": 0.039042,
     "end_time": "2021-05-26T08:34:42.581427",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.542385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename  = '/kaggle/input/mimicdata/train_full.csv'\n",
    "# df_data = pd.read_csv(filename) \n",
    "# (df_data['clean_text'].isnull().values.any())\n",
    "# df_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.646768Z",
     "iopub.status.busy": "2021-05-26T08:34:42.646064Z",
     "iopub.status.idle": "2021-05-26T08:34:42.648327Z",
     "shell.execute_reply": "2021-05-26T08:34:42.648814Z"
    },
    "papermill": {
     "duration": 0.039295,
     "end_time": "2021-05-26T08:34:42.648976",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.609681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_metrics(metrics_hist_all, model_dir):\n",
    "    with open(model_dir + \"/metrics.json\", 'w') as metrics_file:\n",
    "        #concatenate dev, train metrics into one dict\n",
    "        data = metrics_hist_all[0].copy()\n",
    "        data.update({\"%s_te\" % (name):val for (name,val) in metrics_hist_all[1].items()})\n",
    "        data.update({\"%s_tr\" % (name):val for (name,val) in metrics_hist_all[2].items()})\n",
    "        json.dump(data, metrics_file, indent=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.714754Z",
     "iopub.status.busy": "2021-05-26T08:34:42.714055Z",
     "iopub.status.idle": "2021-05-26T08:34:42.719648Z",
     "shell.execute_reply": "2021-05-26T08:34:42.720453Z"
    },
    "papermill": {
     "duration": 0.040687,
     "end_time": "2021-05-26T08:34:42.720634",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.679947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_params_dict(params):\n",
    "    with open(params[\"model_dir\"] + \"/params.json\", 'w') as params_file:\n",
    "        json.dump(params, params_file, indent=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.787911Z",
     "iopub.status.busy": "2021-05-26T08:34:42.787063Z",
     "iopub.status.idle": "2021-05-26T08:34:42.800466Z",
     "shell.execute_reply": "2021-05-26T08:34:42.801039Z"
    },
    "papermill": {
     "duration": 0.046594,
     "end_time": "2021-05-26T08:34:42.801200",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.754606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_preds(yhat, model_dir, hids, fold, ind2c, yhat_raw=None):\n",
    "    \"\"\"\n",
    "        INPUTS:\n",
    "            yhat: binary predictions matrix \n",
    "            model_dir: which directory to save in\n",
    "            hids: list of hadm_id's to save along with predictions\n",
    "            fold: train, dev, or test\n",
    "            ind2c: code lookup\n",
    "            yhat_raw: predicted scores matrix (floats)\n",
    "    \"\"\"\n",
    "    preds_file = \"%s/preds_%s.psv\" % (model_dir, fold)\n",
    "    with open(preds_file, 'w') as f:\n",
    "        w = csv.writer(f, delimiter='|')\n",
    "        for yhat_, hid in zip(yhat, hids):\n",
    "            codes = [ind2c[ind] for ind in np.nonzero(yhat_)[0]]\n",
    "            if len(codes) == 0:\n",
    "                w.writerow([hid, ''])\n",
    "            else:\n",
    "                w.writerow([hid] + list(codes))\n",
    "    if fold != 'train' and yhat_raw is not None:\n",
    "        #write top 100 scores so we can re-do @k metrics later\n",
    "        #top 100 only - saving the full set of scores is very large (~1G for mimic-3 full test set)\n",
    "        scores_file = '%s/pred_100_scores_%s.json' % (model_dir, fold)\n",
    "        scores = {}\n",
    "        sortd = np.argsort(yhat_raw)[:,::-1]\n",
    "        for i,(top_idxs, hid) in enumerate(zip(sortd, hids)):\n",
    "            scores[int(hid)] = {ind2c[idx]: float(yhat_raw[i][idx]) for idx in top_idxs[:100]}\n",
    "        with open(scores_file, 'w') as f:\n",
    "            json.dump(scores, f, indent=1)\n",
    "    return preds_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.866433Z",
     "iopub.status.busy": "2021-05-26T08:34:42.865475Z",
     "iopub.status.idle": "2021-05-26T08:34:42.875654Z",
     "shell.execute_reply": "2021-05-26T08:34:42.876241Z"
    },
    "papermill": {
     "duration": 0.044441,
     "end_time": "2021-05-26T08:34:42.876408",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.831967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_everything(args, metrics_hist_all, model, model_dir, params, criterion, evaluate=False):\n",
    "    \"\"\"\n",
    "        Save metrics, model, params all in model_dir\n",
    "    \"\"\"\n",
    "    save_metrics(metrics_hist_all, model_dir)\n",
    "    params['model_dir'] = model_dir\n",
    "    save_params_dict(params)\n",
    "\n",
    "    if not evaluate:\n",
    "        #save the model with the best criterion metric\n",
    "        if not np.all(np.isnan(metrics_hist_all[0][criterion])):\n",
    "            if criterion == 'loss_dev': \n",
    "                eval_val = np.nanargmin(metrics_hist_all[0][criterion])\n",
    "            else:\n",
    "                eval_val = np.nanargmax(metrics_hist_all[0][criterion])\n",
    "\n",
    "            if eval_val == len(metrics_hist_all[0][criterion]) - 1:                \n",
    "\n",
    "\t\t#save state dict\n",
    "                sd = model.cpu().state_dict()\n",
    "                torch.save(sd, model_dir + \"/model_best_%s.pth\" % criterion)\n",
    "                if args.gpu:\n",
    "                    model.cuda()\n",
    "    print(\"saved metrics, params, model to directory %s\\n\" % (model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:42.957191Z",
     "iopub.status.busy": "2021-05-26T08:34:42.946483Z",
     "iopub.status.idle": "2021-05-26T08:34:42.969136Z",
     "shell.execute_reply": "2021-05-26T08:34:42.968171Z"
    },
    "papermill": {
     "duration": 0.06382,
     "end_time": "2021-05-26T08:34:42.969326",
     "exception": false,
     "start_time": "2021-05-26T08:34:42.905506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"\n",
    "        This class and the data_generator could probably be replaced with a PyTorch DataLoader\n",
    "    \"\"\"\n",
    "    def __init__(self, desc_embed):\n",
    "        self.docs = []\n",
    "        self.labels = []\n",
    "        #self.hadm_ids = []\n",
    "        self.code_set = set()\n",
    "        self.length = 0\n",
    "        self.max_length = 3000\n",
    "        self.desc_embed = desc_embed\n",
    "        self.descs = []\n",
    "\n",
    "    def add_instance(self, row, ind2c, c2ind, w2ind, dv_dict, num_labels,index2word,w2index):\n",
    "        \"\"\"\n",
    "            Makes an instance to add to this batch from given row data, with a bunch of lookups\n",
    "        \"\"\"\n",
    "        #print (\"\\nCalled Because batch size is not same as so called from instance\")\n",
    "        labels = set()\n",
    "        #hadm_id = int(row[1])\n",
    "        text = row['clean_text'].rstrip('\\n')\n",
    "        #print( )\n",
    "        length = int(row['length'])\n",
    "        cur_code_set = set()\n",
    "        labels_idx = np.zeros(num_labels)\n",
    "        labelled = False\n",
    "        desc_vecs = []\n",
    "        #get codes as a multi-hot vector\n",
    "        top_ICD = row['top_ICD']\n",
    "        for badChar in [\"'\", ',','[',']']:\n",
    "            top_ICD = top_ICD.replace(badChar, \"\")\n",
    "        top_ICD = top_ICD.split()\n",
    "        #print(\"\\nhere is the top ICD Code\\n\",top_ICD)\n",
    "        for l in top_ICD:\n",
    "            if l in c2ind.keys():\n",
    "                code = int(c2ind[l])\n",
    "                labels_idx[code] = 1\n",
    "                cur_code_set.add(code)\n",
    "                labelled = True\n",
    "        if not labelled:\n",
    "            print(\"\\n no label has been found\")\n",
    "            return\n",
    "        if self.desc_embed:\n",
    "            for code in cur_code_set:\n",
    "                l = ind2c[code]\n",
    "                if l in dv_dict.keys():\n",
    "                    #need to copy or description padding will get screwed up\n",
    "                    desc_vecs.append(dv_dict[l][:])\n",
    "                else:\n",
    "                    desc_vecs.append([len(w2index)+1])\n",
    "        #OOV words are given a unique index at end of vocab lookup\n",
    "        #print(\"\\nhere is the truncated long text\\n\",text)\n",
    "        text = [int(w2index[w]) if w in w2index else len(w2index) for w in text.split()]\n",
    "        #truncate long documents\n",
    "        if len(text) > self.max_length:\n",
    "            text = text[:self.max_length]\n",
    "        \n",
    "\n",
    "        #build instance\n",
    "        self.docs.append(text)\n",
    "        self.labels.append(labels_idx)\n",
    "        #self.hadm_ids.append(hadm_id)\n",
    "        self.code_set = self.code_set.union(cur_code_set)\n",
    "        if self.desc_embed:\n",
    "            self.descs.append(pad_desc_vecs(desc_vecs))\n",
    "        #reset length\n",
    "        self.length = min(self.max_length, length)\n",
    "\n",
    "    def pad_docs(self):\n",
    "        #pad all docs to have self.length\n",
    "        padded_docs = []\n",
    "        for doc in self.docs:\n",
    "            if len(doc) < self.length:\n",
    "                doc.extend([0] * (self.length - len(doc)))\n",
    "            padded_docs.append(doc)\n",
    "        self.docs = padded_docs\n",
    "\n",
    "    def to_ret(self):\n",
    "        return np.array(self.docs), np.array(self.labels), self.code_set,\\\n",
    "               np.array(self.descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.041188Z",
     "iopub.status.busy": "2021-05-26T08:34:43.040402Z",
     "iopub.status.idle": "2021-05-26T08:34:43.051229Z",
     "shell.execute_reply": "2021-05-26T08:34:43.050606Z"
    },
    "papermill": {
     "duration": 0.048453,
     "end_time": "2021-05-26T08:34:43.051346",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.002893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_param_dict(args):\n",
    "    \"\"\"\n",
    "        Make a list of parameters to save for future reference\n",
    "    \"\"\"\n",
    "    param_vals = [args.Y, args.filter_size, args.dropout, args.num_filter_maps, args.rnn_dim, args.cell_type, args.rnn_layers, \n",
    "                  args.lmbda, args.command, args.weight_decay, args.version, args.data_path, args.vocab, args.embed_file, args.lr]\n",
    "    param_names = [\"Y\", \"filter_size\", \"dropout\", \"num_filter_maps\", \"rnn_dim\", \"cell_type\", \"rnn_layers\", \"lmbda\", \"command\",\n",
    "                   \"weight_decay\", \"version\", \"data_path\", \"vocab\", \"embed_file\", \"lr\"]\n",
    "    params = {name:val for name, val in zip(param_names, param_vals) if val is not None}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.133567Z",
     "iopub.status.busy": "2021-05-26T08:34:43.129253Z",
     "iopub.status.idle": "2021-05-26T08:34:43.137787Z",
     "shell.execute_reply": "2021-05-26T08:34:43.137003Z"
    },
    "papermill": {
     "duration": 0.052791,
     "end_time": "2021-05-26T08:34:43.137912",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.085121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(embed_file, dicts):\n",
    "    #also normalizes the embeddings\n",
    "    W = []\n",
    "    w2ind = dicts['w2ind']\n",
    "    vocab = []\n",
    "    model = KeyedVectors.load_word2vec_format(embed_file, binary=True)\n",
    "    number_of_unknowntoken = 0\n",
    "    i = 0\n",
    "    for word in (w2ind.keys()):\n",
    "        if word not in model:\n",
    "           number_of_unknowntoken += 1\n",
    "        else:\n",
    "            vocab.append(word)\n",
    "            vec = np.array(model[word]).astype(np.float)\n",
    "            vec = vec / float(np.linalg.norm(vec) + 1e-6)\n",
    "            W.append(vec)\n",
    "        i +=1\n",
    "    w2index = {w:i for i,w in enumerate(vocab)}\n",
    "    #print (\"\\n adding unk embedding\",number_of_unknowntoken,len(w2ind.keys()))\n",
    "    vec = np.random.randn(len(W[-1]))\n",
    "    vec = vec / float(np.linalg.norm(vec) + 1e-6)\n",
    "    W.append(vec)\n",
    "    W = np.array(W)\n",
    "    #print(\"\\n Size of the word vector list is\",len(W),len(w2index))\n",
    "    return W,w2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.219943Z",
     "iopub.status.busy": "2021-05-26T08:34:43.219225Z",
     "iopub.status.idle": "2021-05-26T08:34:43.233930Z",
     "shell.execute_reply": "2021-05-26T08:34:43.234764Z"
    },
    "papermill": {
     "duration": 0.063811,
     "end_time": "2021-05-26T08:34:43.234961",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.171150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, Y, embed_file, dicts, lmbda=0, dropout=0.5, gpu=True, embed_size=200):\n",
    "        super(BaseModel, self).__init__()\n",
    "        torch.manual_seed(1337)\n",
    "        self.gpu = gpu\n",
    "        self.Y = Y\n",
    "        self.embed_size = embed_size\n",
    "        self.embed_drop = nn.Dropout(p=dropout)\n",
    "        self.lmbda = lmbda\n",
    "        #print (\"\\Base model initialization has been called\")\n",
    "        #make embedding layer\n",
    "        if embed_file:\n",
    "            print(\"loading pretrained embeddings...\")\n",
    "            W_mod,w2index = load_embeddings(embed_file, dicts)\n",
    "            W = torch.Tensor(W_mod)\n",
    "            print (W.size()[1], W.size()[0])\n",
    "            self.embed = nn.Embedding(W.size()[0], W.size()[1], padding_idx=0)\n",
    "            self.embed.weight.data = W.clone()\n",
    "        else:\n",
    "            #add 2 to include UNK and PAD\n",
    "            vocab_size = len(dicts['ind2w'])\n",
    "            self.embed = nn.Embedding(vocab_size+2, embed_size, padding_idx=0)\n",
    "            \n",
    "\n",
    "    def _get_loss(self, yhat, target, diffs=None):\n",
    "        #calculate the BCE\n",
    "        loss = F.binary_cross_entropy_with_logits(yhat, target)\n",
    "\n",
    "        #add description regularization loss if relevant\n",
    "        if self.lmbda > 0 and diffs is not None:\n",
    "            diff = torch.stack(diffs).mean()\n",
    "            loss = loss + diff\n",
    "        return loss\n",
    "\n",
    "    def embed_descriptions(self, desc_data, gpu):\n",
    "        #label description embedding via convolutional layer\n",
    "        #number of labels is inconsistent across instances, so have to iterate over the batch\n",
    "        b_batch = []\n",
    "        for inst in desc_data:\n",
    "            if len(inst) > 0:\n",
    "                if gpu:\n",
    "                    lt = Variable(torch.cuda.LongTensor(inst))\n",
    "                else:\n",
    "                    lt = Variable(torch.LongTensor(inst))\n",
    "                d = self.desc_embedding(lt)\n",
    "                d = d.transpose(1,2)\n",
    "                d = self.label_conv(d)\n",
    "                d = F.max_pool1d(F.tanh(d), kernel_size=d.size()[2])\n",
    "                d = d.squeeze(2)\n",
    "                b_inst = self.label_fc1(d)\n",
    "                b_batch.append(b_inst)\n",
    "            else:\n",
    "                b_batch.append([])\n",
    "        return b_batch\n",
    "\n",
    "    def _compare_label_embeddings(self, target, b_batch, desc_data):\n",
    "        #description regularization loss \n",
    "        #b is the embedding from description conv\n",
    "        #iterate over batch because each instance has different # labels\n",
    "        diffs = []\n",
    "        for i,bi in enumerate(b_batch):\n",
    "            ti = target[i]\n",
    "            inds = torch.nonzero(ti.data).squeeze().cpu().numpy()\n",
    "\n",
    "            zi = self.final.weight[inds,:]\n",
    "            diff = (zi - bi).mul(zi - bi).mean()\n",
    "\n",
    "            #multiply by number of labels to make sure overall mean is balanced with regard to number of labels\n",
    "            diffs.append(self.lmbda*diff*bi.size()[0])\n",
    "        return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.324329Z",
     "iopub.status.busy": "2021-05-26T08:34:43.313663Z",
     "iopub.status.idle": "2021-05-26T08:34:43.334187Z",
     "shell.execute_reply": "2021-05-26T08:34:43.333538Z"
    },
    "papermill": {
     "duration": 0.068346,
     "end_time": "2021-05-26T08:34:43.334308",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.265962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvAttnPool(BaseModel):\n",
    "\n",
    "    def __init__(self, Y, embed_file, kernel_size, num_filter_maps, lmbda, gpu, dicts, embed_size=200, dropout=0.5, code_emb=None):\n",
    "        super(ConvAttnPool, self).__init__(Y, embed_file, dicts, lmbda, dropout=dropout, gpu=gpu, embed_size=embed_size)\n",
    "\n",
    "        #initialize conv layer as in 2.1\n",
    "        #print (\"\\nConvolution attention model has been called\")\n",
    "        self.conv = nn.Conv1d(self.embed_size, num_filter_maps, kernel_size=kernel_size, padding=int(floor(kernel_size/2)))\n",
    "        xavier_uniform(self.conv.weight)\n",
    "\n",
    "        #context vectors for computing attention as in 2.2\n",
    "        self.U = nn.Linear(num_filter_maps, Y)\n",
    "        xavier_uniform(self.U.weight)\n",
    "\n",
    "        #final layer: create a matrix to use for the L binary classifiers as in 2.3\n",
    "        self.final = nn.Linear(num_filter_maps, Y)\n",
    "        xavier_uniform(self.final.weight)\n",
    "\n",
    "        #initialize with trained code embeddings if applicable\n",
    "        if code_emb:\n",
    "            self._code_emb_init(code_emb, dicts)\n",
    "            #also set conv weights to do sum of inputs\n",
    "            weights = torch.eye(self.embed_size).unsqueeze(2).expand(-1,-1,kernel_size)/kernel_size\n",
    "            self.conv.weight.data = weights.clone()\n",
    "            self.conv.bias.data.zero_()\n",
    "        \n",
    "        #conv for label descriptions as in 2.5\n",
    "        #description module has its own embedding and convolution layers\n",
    "        if lmbda > 0:\n",
    "            W = self.embed.weight.data\n",
    "            self.desc_embedding = nn.Embedding(W.size()[0], W.size()[1], padding_idx=0)\n",
    "            self.desc_embedding.weight.data = W.clone()\n",
    "\n",
    "            self.label_conv = nn.Conv1d(self.embed_size, num_filter_maps, kernel_size=kernel_size, padding=int(floor(kernel_size/2)))\n",
    "            xavier_uniform(self.label_conv.weight)\n",
    "\n",
    "            self.label_fc1 = nn.Linear(num_filter_maps, num_filter_maps)\n",
    "            xavier_uniform(self.label_fc1.weight)\n",
    "\n",
    "    def _code_emb_init(self, code_emb, dicts):\n",
    "        code_embs = KeyedVectors.load_word2vec_format(code_emb)\n",
    "        weights = np.zeros(self.final.weight.size())\n",
    "        for i in range(self.Y):\n",
    "            code = dicts['ind2c'][i]\n",
    "            weights[i] = code_embs[code]\n",
    "        self.U.weight.data = torch.Tensor(weights).clone()\n",
    "        self.final.weight.data = torch.Tensor(weights).clone()\n",
    "        \n",
    "    def forward(self, x, target, desc_data=None, get_attention=True):\n",
    "        #print(\"\\nvalue of x\",x,'\\nShape of X',x.shape) \n",
    "        #get embeddings and apply dropout\n",
    "        x = self.embed(x)\n",
    "        x = self.embed_drop(x)\n",
    "        #print (\"\\nPrinting the shape of the x matri \",x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        #apply convolution and nonlinearity (tanh)\n",
    "        x = F.tanh(self.conv(x).transpose(1,2))\n",
    "        #apply attention\n",
    "        alpha = F.softmax(self.U.weight.matmul(x.transpose(1,2)), dim=2)\n",
    "        #print(\"dimension of alpha\",alpha.shape)\n",
    "        #document representations are weighted sums using the attention. Can compute all at once as a matmul\n",
    "        m = alpha.matmul(x)\n",
    "        #final layer classification\n",
    "        y = self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
    "        \n",
    "        if desc_data is not None:\n",
    "            #run descriptions through description module\n",
    "            b_batch = self.embed_descriptions(desc_data, self.gpu)\n",
    "            #get l2 similarity loss\n",
    "            diffs = self._compare_label_embeddings(target, b_batch, desc_data)\n",
    "        else:\n",
    "            diffs = None\n",
    "            \n",
    "        #final sigmoid to get predictions\n",
    "        yhat = y\n",
    "        loss = self._get_loss(yhat, target, diffs)\n",
    "        return yhat, loss, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.411646Z",
     "iopub.status.busy": "2021-05-26T08:34:43.405901Z",
     "iopub.status.idle": "2021-05-26T08:34:43.417965Z",
     "shell.execute_reply": "2021-05-26T08:34:43.416641Z"
    },
    "papermill": {
     "duration": 0.05241,
     "end_time": "2021-05-26T08:34:43.418151",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.365741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_model(args, dicts):\n",
    "    \"\"\"\n",
    "        Use args to initialize the appropriate model\n",
    "    \"\"\"\n",
    "    Y = len(dicts['ind2c'])\n",
    "    if args.model == \"rnn\":\n",
    "        model = models.VanillaRNN(Y, args.embed_file, dicts, args.rnn_dim, args.cell_type, args.rnn_layers, args.gpu, args.embed_size,\n",
    "                                  args.bidirectional)\n",
    "    elif args.model == \"cnn_vanilla\":\n",
    "        filter_size = int(args.filter_size)\n",
    "        model = models.VanillaConv(Y, args.embed_file, filter_size, args.num_filter_maps, args.gpu, dicts, args.embed_size, args.dropout)\n",
    "    elif args.model == \"conv_attn\":\n",
    "        filter_size = int(args.filter_size)\n",
    "        model = ConvAttnPool(Y, args.embed_file, filter_size, args.num_filter_maps, args.lmbda, args.gpu, dicts,\n",
    "                                    embed_size=args.embed_size, dropout=args.dropout, code_emb=args.code_emb)\n",
    "    elif args.model == \"logreg\":\n",
    "        model = models.BOWPool(Y, args.embed_file, args.lmbda, args.gpu, dicts, args.pool, args.embed_size, args.dropout, args.code_emb)\n",
    "    if args.test_model:\n",
    "        sd = torch.load(args.test_model)\n",
    "        model.load_state_dict(sd)\n",
    "    if args.gpu:\n",
    "        model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.496090Z",
     "iopub.status.busy": "2021-05-26T08:34:43.495072Z",
     "iopub.status.idle": "2021-05-26T08:34:43.498957Z",
     "shell.execute_reply": "2021-05-26T08:34:43.498193Z"
    },
    "papermill": {
     "duration": 0.046918,
     "end_time": "2021-05-26T08:34:43.499115",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.452197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_code_descriptions(args, version='mimic3'):#Have to load the code decription so file pth has to be changed\n",
    "    #load description lookup from the appropriate data files\n",
    "    desc_dict = defaultdict(str)\n",
    "    if version == 'mimic2':\n",
    "        with open('%s/MIMIC_ICD9_mapping' % MIMIC_2_DIR, 'r') as f:\n",
    "            r = csv.reader(f)\n",
    "            #header\n",
    "            next(r)\n",
    "            for row in r:\n",
    "                desc_dict[str(row[1])] = str(row[2])\n",
    "    else:\n",
    "        df  = pd.read_csv(\"%s/ICD_desc_with_freq.csv\" % (args.data_path))\n",
    "        code_desc = df[:2833]\n",
    "        for index, row in code_desc.iterrows():\n",
    "            codeText = row['Long Description']\n",
    "            code = row['Code']\n",
    "            desc_dict[code] = codeText.rstrip('\\n')\n",
    "    return desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.575875Z",
     "iopub.status.busy": "2021-05-26T08:34:43.574972Z",
     "iopub.status.idle": "2021-05-26T08:34:43.581145Z",
     "shell.execute_reply": "2021-05-26T08:34:43.581746Z"
    },
    "papermill": {
     "duration": 0.050329,
     "end_time": "2021-05-26T08:34:43.581907",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.531578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_full_codes(train_path, version='mimic3'):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            train_path: path to train dataset\n",
    "            version: which (MIMIC) dataset\n",
    "        Outputs:\n",
    "            code lookup, description lookup\n",
    "    \"\"\"\n",
    "    #get description lookup\n",
    "    desc_dict = load_code_descriptions(args, version=version)\n",
    "    #print (\"\\n code description disctionary has been generated\", len(desc_dict.keys()))\n",
    "    #build code lookups from appropriate datasets\n",
    "    if version == 'mimic2':\n",
    "        ind2c = defaultdict(str)\n",
    "        codes = set()\n",
    "        with open('%s/proc_dsums.csv' % MIMIC_2_DIR, 'r') as f:\n",
    "            r = csv.reader(f)\n",
    "            #header\n",
    "            next(r)\n",
    "            for row in r:\n",
    "                codes.update(set(row[-1].split(';')))\n",
    "        codes = set([c for c in codes if c != ''])\n",
    "        ind2c = defaultdict(str, {i:c for i,c in enumerate(sorted(codes))})\n",
    "    else:\n",
    "        codes = set()\n",
    "        for split in ['validation','train', 'test']:\n",
    "            df = pd.read_csv('%s/%s_full.csv'%(train_path,split))\n",
    "            for index, row in df.iterrows():\n",
    "                icd_codes = row['top_ICD']\n",
    "                #print ('\\n',type(icd_codes), icd_codes)\n",
    "                for noise in [\"'\", ',','[',']']:\n",
    "                    icd_codes = icd_codes.replace(noise,\"\")\n",
    "                icd_codes = icd_codes.split()\n",
    "                #print (\"\\n after removal of noise\", icd_codes)\n",
    "                for code in icd_codes:\n",
    "                    codes.add(code)\n",
    "                        #codes.add(code)\n",
    "        codes = set([c for c in codes if c != ''])\n",
    "        ind2c = defaultdict(str, {i:c for i,c in enumerate(sorted(codes))})\n",
    "        #print (\"\\n code to indices dict\", len(ind2c.keys()))\n",
    "    return ind2c, desc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.648982Z",
     "iopub.status.busy": "2021-05-26T08:34:43.648261Z",
     "iopub.status.idle": "2021-05-26T08:34:43.657721Z",
     "shell.execute_reply": "2021-05-26T08:34:43.658561Z"
    },
    "papermill": {
     "duration": 0.043775,
     "end_time": "2021-05-26T08:34:43.658761",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.614986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_vocab_dict(args, vocab_file):\n",
    "    #reads vocab_file into two lookups (word:ind) and (ind:word)\n",
    "    vocab = set()\n",
    "    df  = pd.read_csv(vocab_file)\n",
    "    #print (\"\\n columns of vocab file\",df.columns)\n",
    "    #with open(vocab_file, 'r') as vocabfile:\n",
    "    for i,line in (df.iterrows()):\n",
    "        text = line['vocab']\n",
    "        vocab.add(text.rstrip('\\n'))\n",
    "    #hack because the vocabs were created differently for these models\n",
    "    if args.public_model and args.Y == 'full' and args.version == \"mimic3\" and args.model == 'conv_attn':\n",
    "        ind2w = {i:w for i,w in enumerate(sorted(vocab))}\n",
    "    else:\n",
    "        ind2w = {i+1:w for i,w in enumerate(sorted(vocab))}\n",
    "    w2ind = {w:i for i,w in ind2w.items()}\n",
    "    #print (\"\\n vocab size is\", len(w2ind.keys()))\n",
    "    return ind2w, w2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.724595Z",
     "iopub.status.busy": "2021-05-26T08:34:43.723886Z",
     "iopub.status.idle": "2021-05-26T08:34:43.738604Z",
     "shell.execute_reply": "2021-05-26T08:34:43.739265Z"
    },
    "papermill": {
     "duration": 0.048045,
     "end_time": "2021-05-26T08:34:43.739432",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.691387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_lookups(args, desc_embed=False):#desc_embed has to be false as it is CAML Model \n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            args: Input arguments\n",
    "            desc_embed: true if using DR-CAML\n",
    "        Outputs:\n",
    "            vocab lookups, ICD code lookups, description lookup, description one-hot vector lookup\n",
    "    \"\"\"\n",
    "    #get vocab lookups\n",
    "    ind2w, w2ind = load_vocab_dict(args, args.vocab)# This will return deictionary of vocab and their index \n",
    "\n",
    "    #get code and description lookups\n",
    "    if args.Y == 'full':\n",
    "        ind2c, desc_dict = load_full_codes(args.data_path, version=args.version)\n",
    "        #print (\"\\n full codes have to be loaded\")\n",
    "    else:\n",
    "        codes = set()\n",
    "        with open(\"%s/TOP_%s_CODES.csv\" % (MIMIC_3_DIR, str(args.Y)), 'r') as labelfile:\n",
    "            lr = csv.reader(labelfile)\n",
    "            for i,row in enumerate(lr):\n",
    "                codes.add(row[0])\n",
    "        ind2c = {i:c for i,c in enumerate(sorted(codes))}\n",
    "        desc_dict = load_code_descriptions(args)\n",
    "    c2ind = {c:i for i,c in ind2c.items()}\n",
    "\n",
    "    #get description one-hot vector lookup\n",
    "    if desc_embed:\n",
    "        dv_dict = load_description_vectors(args.Y, version=args.version)\n",
    "    else:\n",
    "        dv_dict = None\n",
    "    print(\"\\nSaving the code dict\")\n",
    "    with open('IndecCodeDict.txt', 'w') as w:\n",
    "        for i, j in ind2c.items():\n",
    "            w.write(\"%s\\t%s\\n\"%(i,j))\n",
    "        w.close()\n",
    "        \n",
    "\n",
    "    #dicts = {'ind2w': ind2w, 'w2ind': w2ind}\n",
    "    dicts = {'ind2w': ind2w, 'w2ind': w2ind, 'ind2c': ind2c, 'c2ind': c2ind, 'desc': desc_dict, 'dv': dv_dict}\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.809475Z",
     "iopub.status.busy": "2021-05-26T08:34:43.808580Z",
     "iopub.status.idle": "2021-05-26T08:34:43.818196Z",
     "shell.execute_reply": "2021-05-26T08:34:43.818870Z"
    },
    "papermill": {
     "duration": 0.046338,
     "end_time": "2021-05-26T08:34:43.819039",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.772701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_param_dict(args):\n",
    "    \"\"\"\n",
    "        Make a list of parameters to save for future reference\n",
    "    \"\"\"\n",
    "    param_vals = [args.Y, args.filter_size, args.dropout, args.num_filter_maps, args.rnn_dim, args.cell_type, args.rnn_layers, \n",
    "                  args.lmbda, args.command, args.weight_decay, args.version, args.data_path, args.vocab, args.embed_file, args.lr]\n",
    "    param_names = [\"Y\", \"filter_size\", \"dropout\", \"num_filter_maps\", \"rnn_dim\", \"cell_type\", \"rnn_layers\", \"lmbda\", \"command\",\n",
    "                   \"weight_decay\", \"version\", \"data_path\", \"vocab\", \"embed_file\", \"lr\"]\n",
    "    params = {name:val for name, val in zip(param_names, param_vals) if val is not None}\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.886939Z",
     "iopub.status.busy": "2021-05-26T08:34:43.886226Z",
     "iopub.status.idle": "2021-05-26T08:34:43.895805Z",
     "shell.execute_reply": "2021-05-26T08:34:43.896487Z"
    },
    "papermill": {
     "duration": 0.044336,
     "end_time": "2021-05-26T08:34:43.896659",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.852323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init(args):\n",
    "    \"\"\"\n",
    "        Load data, build model, create optimizer, create vars to hold metrics, etc.\n",
    "    \"\"\"\n",
    "    #need to handle really large text fields\n",
    "    #dicts = {'ind2w': ind2w, 'w2ind': w2ind, 'ind2c': ind2c, 'c2ind': c2ind, 'desc': desc_dict, 'dv': dv_dict}\n",
    "    #load vocab and other lookups\n",
    "    desc_embed = args.lmbda > 0\n",
    "    #print(\"loading lookups...\")\n",
    "    dicts = load_lookups(args, desc_embed=desc_embed)\n",
    "    #print (\"\\n Dictionary shape\",(dicts.keys()))\n",
    "    model = pick_model(args, dicts)\n",
    "    print(\"\\n model picking done\")\n",
    "    print(model)\n",
    "\n",
    "    if not args.test_model:\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=args.weight_decay, lr=args.lr)\n",
    "        #print (\"\\noptumizer has been called\")\n",
    "    else:\n",
    "        optimizer = None\n",
    "        #print (\"\\n no optimizer has been called\")\n",
    "\n",
    "    params = make_param_dict(args)\n",
    "    \n",
    "    return args, model, optimizer, params, dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:43.968905Z",
     "iopub.status.busy": "2021-05-26T08:34:43.967998Z",
     "iopub.status.idle": "2021-05-26T08:34:43.982116Z",
     "shell.execute_reply": "2021-05-26T08:34:43.982688Z"
    },
    "papermill": {
     "duration": 0.053375,
     "end_time": "2021-05-26T08:34:43.982843",
     "exception": false,
     "start_time": "2021-05-26T08:34:43.929468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_generator(filename, dicts, batch_size, num_labels,index2word,w2index, desc_embed=False, version='mimic3'):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            filename: holds data sorted by sequence length, for best batching\n",
    "            dicts: holds all needed lookups\n",
    "            batch_size: the batch size for train iterations\n",
    "            num_labels: size of label output space\n",
    "            desc_embed: true if using DR-CAML (lambda > 0)\n",
    "            version: which (MIMIC) dataset\n",
    "        Yields:\n",
    "            np arrays with data for training loop.\n",
    "    \"\"\"\n",
    "    ind2w, w2ind, ind2c, c2ind, dv_dict = dicts['ind2w'], dicts['w2ind'], dicts['ind2c'], dicts['c2ind'], dicts['dv']\n",
    "    if('validation' in filename):\n",
    "        df  = pd.read_csv(filename)\n",
    "        #df  = df[:10]#Change\n",
    "    elif ('test' in filename):\n",
    "        df  = pd.read_csv(filename)\n",
    "        df  = df[:10]#Change\n",
    "    else:\n",
    "        df  = pd.read_csv(os.path.join(filename,'train_full.csv'))\n",
    "        #df = df[:20000]#CHange\n",
    "    #with open(filename, 'r') as infile:\n",
    "        #r = csv.reader(infile)\n",
    "        #header\n",
    "        #next(r)\n",
    "    cur_inst = Batch(desc_embed)\n",
    "    #print(\"\\nCheck point for batch creation\",cur_inst.docs, cur_inst.labels,cur_inst.max_length, cur_inst.desc_embed)\n",
    "    for index, row in df.iterrows():\n",
    "        top_ICD = row['top_ICD']\n",
    "        for badChar in [\"'\", ',','[',']']:\n",
    "            top_ICD = top_ICD.replace(badChar, \"\")\n",
    "        top_ICD = top_ICD.split()\n",
    "        if not len(row['clean_text']) or not len(top_ICD):\n",
    "            print (\"\\nHere we raw text is empty for doc number\",index)\n",
    "            continue\n",
    "        #print (\"\\nDocument number\", index)\n",
    "        #print (\"\\nhere is the length of the number of docs and batch size\",len(cur_inst.docs), batch_size)\n",
    "        #find the next `batch_size` instances\n",
    "        if len(cur_inst.docs) == batch_size:\n",
    "            #print (\"\\nhere is the length of the number of docs and batch size when they are equal\",len(cur_inst.docs), batch_size)\n",
    "            cur_inst.pad_docs()\n",
    "            yield cur_inst.to_ret()\n",
    "            #clear\n",
    "            cur_inst = Batch(desc_embed)\n",
    "        cur_inst.add_instance(row, ind2c, c2ind, w2ind, dv_dict, num_labels,index2word,w2index)\n",
    "        cur_inst.pad_docs()\n",
    "        yield cur_inst.to_ret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.051467Z",
     "iopub.status.busy": "2021-05-26T08:34:44.050732Z",
     "iopub.status.idle": "2021-05-26T08:34:44.067723Z",
     "shell.execute_reply": "2021-05-26T08:34:44.068315Z"
    },
    "papermill": {
     "duration": 0.052201,
     "end_time": "2021-05-26T08:34:44.068468",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.016267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, Y, epoch, batch_size, data_path, gpu, version, dicts, quiet,index2word,w2index):\n",
    "    \"\"\"\n",
    "        Training loop.\n",
    "        output: losses for each example for this iteration\n",
    "    \"\"\"\n",
    "    print(\"EPOCH %d\" % epoch)\n",
    "    num_labels = len(dicts['ind2c'])\n",
    "\n",
    "    losses = []\n",
    "    #how often to print some info to stdout\n",
    "    print_every = 25\n",
    "\n",
    "    ind2w, w2ind, ind2c, c2ind = dicts['ind2w'], dicts['w2ind'], dicts['ind2c'], dicts['c2ind']\n",
    "    unseen_code_inds = set(ind2c.keys())\n",
    "    desc_embed = model.lmbda > 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    gen = data_generator(data_path, dicts, batch_size, num_labels, index2word,w2index,version=version, desc_embed=desc_embed)\n",
    "    #print (\"\\nData type of the gen\",type(gen))\n",
    "    for batch_idx, tup in tqdm(enumerate(gen)):\n",
    "        data, target, code_set, descs = tup\n",
    "        #print(\"\\nhere is the desc\",descs)\n",
    "        data, target = Variable(torch.LongTensor(data)), Variable(torch.FloatTensor(target))\n",
    "        unseen_code_inds = unseen_code_inds.difference(code_set)\n",
    "        if gpu:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()#To zero out the gradient before back propogation step up specially during RNN Model training \n",
    "\n",
    "        if desc_embed:\n",
    "            desc_data = descs\n",
    "        else:\n",
    "            desc_data = None\n",
    "        #print (\"\\nData for training the model\",data.shape, \"\\n\",target.shape,)\n",
    "        output, loss, _ = model(data, target, desc_data=desc_data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print (\"\\nModel training of one batch has been done, saving loss value\", data)\n",
    "        losses.append(loss.data)\n",
    "\n",
    "        if not quiet and batch_idx % print_every == 0:\n",
    "            print (\"\\nthe average loss of the last 10 batches\\n\")\n",
    "            print(\"Train epoch: {} [batch #{}, batch_size {}, seq length {}]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_idx, data.size()[0], data.size()[1], np.mean([x.item() for x in losses[-10:]])))\n",
    "    return losses, unseen_code_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.134604Z",
     "iopub.status.busy": "2021-05-26T08:34:44.133807Z",
     "iopub.status.idle": "2021-05-26T08:34:44.152457Z",
     "shell.execute_reply": "2021-05-26T08:34:44.153075Z"
    },
    "papermill": {
     "duration": 0.054244,
     "end_time": "2021-05-26T08:34:44.153231",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.098987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_epoch(model, optimizer, Y, epoch, n_epochs, batch_size, data_path, version, testing, dicts, model_dir, \n",
    "              samples, gpu, quiet,index2word,w2index):\n",
    "    \"\"\"\n",
    "        Wrapper to do a training epoch and test on dev\n",
    "    \"\"\"\n",
    "    if not testing:\n",
    "        losses, unseen_code_inds = train(model, optimizer, Y, epoch, batch_size, data_path, gpu, version, dicts, quiet,index2word,w2index)\n",
    "        loss = np.mean([x.item() for x in losses[-10:]])\n",
    "        print(\"epoch loss: \" + str(loss))\n",
    "    else:\n",
    "        loss = np.nan\n",
    "        if model.lmbda > 0:\n",
    "            #still need to get unseen code inds\n",
    "            print(\"getting set of codes not in training set\")\n",
    "            c2ind = dicts['c2ind']\n",
    "            unseen_code_inds = set(dicts['ind2c'].keys())\n",
    "            num_labels = len(dicts['ind2c'])\n",
    "            with open(data_path, 'r') as f:\n",
    "                r = csv.reader(f)\n",
    "                #header\n",
    "                next(r)\n",
    "                for row in r:\n",
    "                    unseen_code_inds = unseen_code_inds.difference(set([c2ind[c] for c in row[3].split(';') if c != '']))\n",
    "            print(\"num codes not in train set: %d\" % len(unseen_code_inds))\n",
    "        else:\n",
    "            unseen_code_inds = set()\n",
    "\n",
    "    fold = 'test' if version == 'mimic2' else 'validation'\n",
    "    if epoch == n_epochs - 1:\n",
    "        print(\"last epoch: testing on test and train sets\")\n",
    "        testing = True\n",
    "        quiet = False\n",
    "\n",
    "    #test on validation\n",
    "    metrics = test(model, Y, epoch, data_path, fold, gpu, version, unseen_code_inds, dicts, samples, model_dir,\n",
    "                   testing,index2word,w2index)\n",
    "    if testing or epoch == n_epochs - 1:\n",
    "        print(\"\\nevaluating on test\")\n",
    "        metrics_te = test(model, Y, epoch, data_path, \"test\", gpu, version, unseen_code_inds, dicts, samples, \n",
    "                          model_dir, True,index2word,w2index)\n",
    "    else:\n",
    "        metrics_te = defaultdict(float)\n",
    "        fpr_te = defaultdict(lambda: [])\n",
    "        tpr_te = defaultdict(lambda: [])\n",
    "    metrics_tr = {'loss': loss}\n",
    "    metrics_all = (metrics, metrics_te, metrics_tr)\n",
    "    return metrics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.221081Z",
     "iopub.status.busy": "2021-05-26T08:34:44.220380Z",
     "iopub.status.idle": "2021-05-26T08:34:44.228034Z",
     "shell.execute_reply": "2021-05-26T08:34:44.228605Z"
    },
    "papermill": {
     "duration": 0.04328,
     "end_time": "2021-05-26T08:34:44.228754",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.185474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def early_stop(metrics_hist, criterion, patience):\n",
    "    if not np.all(np.isnan(metrics_hist[criterion])):\n",
    "        if len(metrics_hist[criterion]) >= patience:\n",
    "            if criterion == 'loss_dev': \n",
    "                return np.nanargmin(metrics_hist[criterion]) < len(metrics_hist[criterion]) - patience\n",
    "            else:\n",
    "                return np.nanargmax(metrics_hist[criterion]) < len(metrics_hist[criterion]) - patience\n",
    "    else:\n",
    "        #keep training if criterion results have all been nan so far\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.036632,
     "end_time": "2021-05-26T08:34:44.296766",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.260134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.365420Z",
     "iopub.status.busy": "2021-05-26T08:34:44.364694Z",
     "iopub.status.idle": "2021-05-26T08:34:44.385403Z",
     "shell.execute_reply": "2021-05-26T08:34:44.385950Z"
    },
    "papermill": {
     "duration": 0.05617,
     "end_time": "2021-05-26T08:34:44.386139",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.329969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epochs(args, model, optimizer, params, dicts):\n",
    "    \"\"\"\n",
    "        Main loop. does train and test\n",
    "    \"\"\"\n",
    "    metrics_hist = defaultdict(lambda: [])\n",
    "    metrics_hist_te = defaultdict(lambda: [])\n",
    "    metrics_hist_tr = defaultdict(lambda: [])\n",
    "\n",
    "    test_only = args.test_model is not None\n",
    "    evaluate = args.test_model is not None\n",
    "    W_mod,w2index = load_embeddings(args.embed_file, dicts) \n",
    "    index2word = {i:w for w,i in w2index.items()}\n",
    "    #train for n_epochs unless criterion metric does not improve for [patience] epochs\n",
    "    for epoch in range(args.n_epochs):\n",
    "        MODEL_DIR = '/kaggle/working/augmented/'#os.path.join(args.data_path, 'model')\n",
    "        #only test on train/test set on very last epoch\n",
    "        if epoch == 0 and not args.test_model:\n",
    "            model_dir = MODEL_DIR #str('_'.join([args.model, time.strftime('%b_%d_%H:%M:%S', time.localtime())]))\n",
    "            if not path.isdir(model_dir):\n",
    "                os.mkdir(model_dir)\n",
    "            #print('\\n model directory path has been created')\n",
    "        elif args.test_model:\n",
    "            model_dir = os.path.dirname(os.path.abspath(args.test_model))\n",
    "        metrics_all = one_epoch(model, optimizer, args.Y, epoch, args.n_epochs, args.batch_size, args.data_path,\n",
    "                                                  args.version, test_only, dicts, model_dir, \n",
    "                                                  args.samples, args.gpu, args.quiet,index2word,w2index)\n",
    "        for name in metrics_all[0].keys():\n",
    "            metrics_hist[name].append(metrics_all[0][name])\n",
    "        for name in metrics_all[1].keys():\n",
    "            metrics_hist_te[name].append(metrics_all[1][name])\n",
    "        for name in metrics_all[2].keys():\n",
    "            metrics_hist_tr[name].append(metrics_all[2][name])\n",
    "        metrics_hist_all = (metrics_hist, metrics_hist_te, metrics_hist_tr)\n",
    "\n",
    "        #save metrics, model, params\n",
    "        save_everything(args, metrics_hist_all, model, model_dir, params, args.criterion, evaluate)\n",
    "\n",
    "        if test_only:\n",
    "            #we're done\n",
    "            break\n",
    "\n",
    "        if args.criterion in metrics_hist.keys():\n",
    "            if early_stop(metrics_hist, args.criterion, args.patience):\n",
    "                #stop training, do tests on test and train sets, and then stop the script\n",
    "                print(\"%s hasn't improved in %d epochs, early stopping...\" % (args.criterion, args.patience))\n",
    "                test_only = True\n",
    "                args.test_model = '%s/model_best_%s.pth' % (model_dir, args.criterion)\n",
    "                model = tools.pick_model(args, dicts)\n",
    "    return epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.459583Z",
     "iopub.status.busy": "2021-05-26T08:34:44.458856Z",
     "iopub.status.idle": "2021-05-26T08:34:44.462273Z",
     "shell.execute_reply": "2021-05-26T08:34:44.462760Z"
    },
    "papermill": {
     "duration": 0.042119,
     "end_time": "2021-05-26T08:34:44.462932",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.420813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.mkdir('/kaggle/working/augmented/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.034713,
     "end_time": "2021-05-26T08:34:44.533091",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.498378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.603778Z",
     "iopub.status.busy": "2021-05-26T08:34:44.603085Z",
     "iopub.status.idle": "2021-05-26T08:34:44.609443Z",
     "shell.execute_reply": "2021-05-26T08:34:44.609980Z"
    },
    "papermill": {
     "duration": 0.041661,
     "end_time": "2021-05-26T08:34:44.610176",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.568515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unseen_code_vecs(model, code_inds, dicts, gpu):\n",
    "    \"\"\"\n",
    "        Use description module for codes not seen in training set.\n",
    "    \"\"\"\n",
    "    code_vecs = build_code_vecs(code_inds, dicts)\n",
    "    code_inds, vecs = code_vecs\n",
    "    #wrap it in an array so it's 3d\n",
    "    desc_embeddings = model.embed_descriptions([vecs], gpu)[0]\n",
    "    #replace relevant final_layer weights with desc embeddings \n",
    "    model.final.weight.data[code_inds, :] = desc_embeddings.data\n",
    "    model.final.bias.data[code_inds] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.683717Z",
     "iopub.status.busy": "2021-05-26T08:34:44.682628Z",
     "iopub.status.idle": "2021-05-26T08:34:44.713931Z",
     "shell.execute_reply": "2021-05-26T08:34:44.714746Z"
    },
    "papermill": {
     "duration": 0.070763,
     "end_time": "2021-05-26T08:34:44.714954",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.644191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, Y, epoch, data_path, fold, gpu, version, code_inds, dicts, samples, model_dir, testing,index2word,w2index):\n",
    "    \"\"\"\n",
    "        Testing loop.\n",
    "        Returns metrics\n",
    "    \"\"\"\n",
    "    file  = fold+'_full.csv'\n",
    "    filename = os.path.join(data_path,file)\n",
    "    print('file for evaluation: %s' % filename)\n",
    "    num_labels = len(dicts['ind2c'])\n",
    "\n",
    "    #initialize stuff for saving attention samples\n",
    "    if samples:\n",
    "        tp_file = open('%s/tp_%s_examples_%d.txt' % (model_dir, fold, epoch), 'w')#Have to give output folder path\n",
    "        fp_file = open('%s/fp_%s_examples_%d.txt' % (model_dir, fold, epoch), 'w')\n",
    "        window_size = model.conv.weight.data.size()[2]\n",
    "\n",
    "    y, yhat, yhat_raw, hids, losses = [], [], [], [], []\n",
    "    ind2w, w2ind, ind2c, c2ind = index2word, w2index, dicts['ind2c'], dicts['c2ind']\n",
    "\n",
    "    desc_embed = model.lmbda > 0\n",
    "    if desc_embed and len(code_inds) > 0:\n",
    "        unseen_code_vecs(model, code_inds, dicts, gpu)\n",
    "    #outfolder = '/kaggle/working/aplhaFolder/'\n",
    "    #if not path.isdir(outfolder):\n",
    "        #os.mkdir(model_dir)\n",
    "    model.eval()\n",
    "    gen = data_generator(filename, dicts, 1, num_labels,index2word,w2index, version=version, desc_embed=desc_embed)\n",
    "    for batch_idx, tup in tqdm(enumerate(gen)):\n",
    "        data, target, hadm_ids, descs = tup\n",
    "        data, target = Variable(torch.LongTensor(data), volatile=True), Variable(torch.FloatTensor(target))\n",
    "        if gpu:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if desc_embed:\n",
    "            desc_data = descs\n",
    "        else:\n",
    "            desc_data = None\n",
    "        \n",
    "        #get an attention sample for 2% of batches\n",
    "        get_attn = samples and (np.random.rand() < 0.02 or (fold == 'test' and testing))\n",
    "        output, loss, alpha = model(data, target, desc_data=desc_data, get_attention=get_attn)#Here print the value of alpha and ind out \n",
    "        #print(\"\\nHere is the alpha value\\n\",batch_idx,\"\\n\",alpha.shape)\n",
    "        #outfile = os.path.join(outfolder,(str(batch_idx)+'.npy'))\n",
    "        outfile = str(batch_idx)+'.npy'\n",
    "        alphaTensor  = torch.tensor(alpha[0],requires_grad=True)\n",
    "        #k.detach().numpy()\n",
    "        #np.save(outfile,np.array(alphaTensor.cpu()))\n",
    "        np.save(outfile,(alphaTensor.cpu()).detach().numpy())\n",
    "        output = F.sigmoid(output)\n",
    "        output = output.data.cpu().numpy()\n",
    "        losses.append(loss.data)\n",
    "        target_data = target.data.cpu().numpy()\n",
    "        if get_attn and samples:\n",
    "            interpret.save_samples(data, output, target_data, alpha, window_size, epoch, tp_file, fp_file, dicts=dicts)\n",
    "\n",
    "        #save predictions, target, hadm ids\n",
    "        #print(\"\\nHere is the targte data and predicted output\\n\",target_data,\"\\n\",output)\n",
    "        yhat_raw.append(output)\n",
    "        output = np.round(output)\n",
    "        y.append(target_data)\n",
    "        yhat.append(output)\n",
    "        hids.extend(hadm_ids)\n",
    "\n",
    "    #close files if needed\n",
    "    if samples:\n",
    "        tp_file.close()\n",
    "        fp_file.close()\n",
    "\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    yhat = np.concatenate(yhat, axis=0)\n",
    "    yhat_raw = np.concatenate(yhat_raw, axis=0)\n",
    "\n",
    "    #write the predictions\n",
    "    preds_file = write_preds(yhat, model_dir, hids, fold, ind2c, yhat_raw)\n",
    "    #get metrics\n",
    "    k = 5 if num_labels == 50 else [8,15]\n",
    "    metrics = all_metrics(yhat, y, k=k, yhat_raw=yhat_raw)\n",
    "    print_metrics(metrics)\n",
    "    metrics['loss_%s' % fold] = np.mean([x.item() for x in losses])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.786460Z",
     "iopub.status.busy": "2021-05-26T08:34:44.785657Z",
     "iopub.status.idle": "2021-05-26T08:34:44.793551Z",
     "shell.execute_reply": "2021-05-26T08:34:44.794096Z"
    },
    "papermill": {
     "duration": 0.045379,
     "end_time": "2021-05-26T08:34:44.794263",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.748884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    start = time.time()\n",
    "    args, model, optimizer, params, dicts = init(args)\n",
    "    print(args.test_model)\n",
    "    epochs_trained = train_epochs(args, model, optimizer, params, dicts)\n",
    "    print ('\\nTrain epochs has been done successfully')\n",
    "    print(\"TOTAL ELAPSED TIME FOR %s MODEL AND %d EPOCHS: %f\" % (args.model, epochs_trained, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T08:34:44.867919Z",
     "iopub.status.busy": "2021-05-26T08:34:44.867101Z",
     "iopub.status.idle": "2021-05-26T08:35:47.604965Z",
     "shell.execute_reply": "2021-05-26T08:35:47.605774Z"
    },
    "papermill": {
     "duration": 62.779236,
     "end_time": "2021-05-26T08:35:47.605948",
     "exception": false,
     "start_time": "2021-05-26T08:34:44.826712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pmcmodel/PMC-w2v.bin\n",
      "\n",
      "Saving the code dict\n",
      "loading pretrained embeddings...\n",
      "200 36315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2aa75af3d9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-5e004110a03c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-cfe70182e437>\u001b[0m in \u001b[0;36minit\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_lookups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print (\"\\n Dictionary shape\",(dicts.keys()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n model picking done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-20db4f416fbc>\u001b[0m in \u001b[0;36mpick_model\u001b[0;34m(args, dicts)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"train a neural network on some clinical documents\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default = '/kaggle/input/mimicdata', \n",
    "                        help=\"path to a file containing sorted train data. dev/test splits assumed to have same name format with 'train' replaced by 'dev' and 'test'\") #Cleaned Text file path of csv file\n",
    "    parser.add_argument(\"--vocab\", type=str, default = '/kaggle/input/vocabdata/vocab_new.csv')#Create Vocabulary on training data set. This has to be created using mimic III datatype\n",
    "    parser.add_argument(\"--Y\", type=str, default = 'full', help=\"size of label space\")\n",
    "    parser.add_argument(\"--model\", type=str, default = 'conv_attn',  help=\"model has to be choosen from the given choice\")#Have to be trained for cnv_attn model \n",
    "    parser.add_argument(\"--n_epochs\", type=int, default = 5, help=\"number of epochs to train\")#Give number of epochs as per paper default is 10\n",
    "    parser.add_argument(\"--embed_file\", type=str, default = '/kaggle/input/pmcmodel/PMC-w2v.bin',\n",
    "                        help=\"path to a file holding pre-trained embeddings\")#Have to use PUBMed embedding \n",
    "    parser.add_argument(\"--cell-type\", type=str, choices=[\"lstm\", \"gru\"], help=\"what kind of RNN to use (default: GRU)\", dest='cell_type',\n",
    "                        default='gru')#do not change \n",
    "    parser.add_argument(\"--rnn-dim\", type=int, required=False, dest=\"rnn_dim\", default=128,\n",
    "                        help=\"size of rnn hidden layer (default: 128)\")#Do not  change \n",
    "    parser.add_argument(\"--bidirectional\", dest=\"bidirectional\", action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag for rnn to use a bidirectional model\")#Do not change\n",
    "    parser.add_argument(\"--rnn-layers\", type=int, required=False, dest=\"rnn_layers\", default=1,\n",
    "                        help=\"number of layers for RNN models (default: 1)\")#Do not change\n",
    "    parser.add_argument(\"--embed-size\", type=int, required=False, dest=\"embed_size\", default=200,\n",
    "                        help=\"size of embedding dimension. (default: 100)\")#Give the dimension of pubmed embedding model \n",
    "    parser.add_argument(\"--filter-size\", type=str, required=False, dest=\"filter_size\", default=4,\n",
    "                        help=\"size of convolution filter to use. (default: 3) For multi_conv_attn, give comma separated integers, e.g. 3,4,5\")# Do not change\n",
    "    parser.add_argument(\"--num-filter-maps\", type=int, required=False, dest=\"num_filter_maps\", default=50,\n",
    "                        help=\"size of conv output (default: 50)\")#Do not change\n",
    "    parser.add_argument(\"--pool\", choices=['max', 'avg'],default = 'max',  required=False, dest=\"pool\", help=\"which type of pooling to do (logreg model only)\")#Use max pooling\n",
    "    parser.add_argument(\"--code-emb\", type=str, required=False, dest=\"code_emb\", \n",
    "                        help=\"point to code embeddings to use for parameter initialization, if applicable\")#Do not change\n",
    "    parser.add_argument(\"--weight-decay\", type=float, required=False, dest=\"weight_decay\", default=0,\n",
    "                        help=\"coefficient for penalizing l2 norm of model weights (default: 0)\")#Do not change\t\n",
    "    parser.add_argument(\"--lr\", type=float, required=False, dest=\"lr\", default=1e-3,\n",
    "                        help=\"learning rate for Adam optimizer (default=1e-3)\")#Do not change\n",
    "    parser.add_argument(\"--batch-size\", type=int, required=False, dest=\"batch_size\", default=16,\n",
    "                        help=\"size of training batches\")#Do not change\n",
    "    parser.add_argument(\"--dropout\", dest=\"dropout\", type=float, required=False, default=0.5,\n",
    "                        help=\"optional specification of dropout (default: 0.5)\")#Do not change \t\n",
    "    parser.add_argument(\"--lmbda\", type=float, required=False, dest=\"lmbda\", default=0,\n",
    "                        help=\"hyperparameter to tradeoff BCE loss and similarity embedding loss. defaults to 0, which won't create/use the description embedding module at all. \")#Do not change\n",
    "    parser.add_argument(\"--dataset\", type=str, choices=['mimic2', 'mimic3'], dest=\"version\", default=  'C:\\\\Users\\\\akuma750\\\\Documents\\\\Project\\\\ICD_RWMD\\\\OrigionalCode\\\\caml-mimic-master\\\\caml-mimic-master\\\\mimicdata\\\\mimic3\\\\data' , required=False,\n",
    "                        help=\"version of MIMIC in use (default: mimic3)\")#Give the path of dataset folder path\n",
    "    parser.add_argument(\"--test-model\", type=str, dest=\"test_model\", required=False, help=\"path to a saved model to load and evaluate\")#Path of saving trained model\n",
    "    parser.add_argument(\"--criterion\", type=str, default='f1_micro', required=False, dest=\"criterion\",\n",
    "                        help=\"which metric to use for early stopping (default: f1_micro)\")\n",
    "    parser.add_argument(\"--patience\", type=int, default=3, required=False,\n",
    "                        help=\"how many epochs to wait for improved criterion metric before early stopping (default: 3)\")#Do not change\n",
    "    parser.add_argument(\"--gpu\", dest=\"gpu\",default= 'gpu', action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag to use GPU if available\")#Do not change\n",
    "    parser.add_argument(\"--public-model\", dest=\"public_model\", action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag for testing pre-trained models from the public github\")#Do not change\n",
    "    parser.add_argument(\"--stack-filters\", dest=\"stack_filters\", action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag for multi_conv_attn to instead use concatenated filter outputs, rather than pooling over them\")#Do not change\n",
    "    parser.add_argument(\"--samples\", dest=\"samples\", action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag to save samples of good / bad predictions\")#Do not change\n",
    "    parser.add_argument(\"--quiet\", dest=\"quiet\", action=\"store_const\", required=False, const=True,\n",
    "                        help=\"optional flag not to print so much during training\")#Do not change\n",
    "    #print(parser.print_help())\n",
    "    args = parser.parse_args(\"\")\n",
    "    command = ' '.join(['python'] + sys.argv)\n",
    "    args.command = command\n",
    "    print (args.embed_file)\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033509,
     "end_time": "2021-05-26T08:35:47.673445",
     "exception": false,
     "start_time": "2021-05-26T08:35:47.639936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033674,
     "end_time": "2021-05-26T08:35:47.740604",
     "exception": false,
     "start_time": "2021-05-26T08:35:47.706930",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033147,
     "end_time": "2021-05-26T08:35:47.807847",
     "exception": false,
     "start_time": "2021-05-26T08:35:47.774700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033054,
     "end_time": "2021-05-26T08:35:47.874701",
     "exception": false,
     "start_time": "2021-05-26T08:35:47.841647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033529,
     "end_time": "2021-05-26T08:35:47.942197",
     "exception": false,
     "start_time": "2021-05-26T08:35:47.908668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 75.595403,
   "end_time": "2021-05-26T08:35:48.084399",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-26T08:34:32.488996",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
