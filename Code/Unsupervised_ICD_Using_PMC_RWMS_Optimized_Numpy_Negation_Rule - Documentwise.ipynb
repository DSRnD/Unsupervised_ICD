{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sourabhbhattacharjee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sourabhbhattacharjee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from keras.models import Model, load_model\n",
    "#from keras.layers import LSTM, Dense, TimeDistributed, Input, Masking, RepeatVector, Bidirectional, Embedding\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "punc = list(string.punctuation)\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from scipy.spatial.distance import cosine\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPER-PARAMETERS\n",
    "\n",
    "num_words = 10000\n",
    "MAX_SEQUENCE_LENGTH = 16\n",
    "WORD_EMBEDDING_DIM = 200\n",
    "batch_size = 640\n",
    "ENCODING_DIM = 500\n",
    "NUM_DATAPOINT = -1 # All in the file\n",
    "NUM_ICD_CODES = 2833\n",
    "NUM_EPOCHS = 2\n",
    "VALIDATION_SPLIT = 0.2\n",
    "PATIENCE = 5\n",
    "TOP_K_PER_SENTENCE = 10\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "THRESHOLD = -1 # TODO\n",
    "\n",
    "ICD_DESC_FILENAME = 'ICD_desc_with_freq.csv'\n",
    "#DD_FILENAME = 'MIMIC_III_Final_1000_clean_shorted.csv'\n",
    "#DD_FILENAME = 'MIMIC-III-Final_5000_clean_shortened.csv'\n",
    "DD_FILENAME = 'MIMIC-III-Final_cleaned.csv'\n",
    "EMB_FILE = 'PMC-w2v.bin'\n",
    "\n",
    "#RESULT_FILENAME = 'Experiment Results.xlsx'\n",
    "#http://yaronvazana.com/2019/09/28/training-an-autoencoder-to-generate-text-embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Sentence Embedding using Average Word Embedding of tokens\n",
    "def get_sentence_embedding(sent, embedding):\n",
    "    words = word_tokenize(sent)\n",
    "    m = len(words)\n",
    "    total_embedding = 0\n",
    "    \n",
    "    #Get wordwise Embeddings as tensors\n",
    "    sent_embedding = np.array([get_word_embedding(word, embedding) for word in words])\n",
    "    \n",
    "    #Get the embedding of sentence by adding embedding tensors\n",
    "    total_embedding = np.sum(sent_embedding, axis = 0)\n",
    "    \n",
    "    try:\n",
    "        return total_embedding/np.linalg.norm(total_embedding, axis = 0, keepdims=True)\n",
    "    except:\n",
    "        #print('sent : ', sent)\n",
    "        #print('m: ', m)\n",
    "        return np.array(total_embedding/np.linalg.norm(total_embedding, axis = 0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Word Embedding\n",
    "def get_word_embedding(word, embedding):\n",
    "    try:\n",
    "        return embedding[word] \n",
    "    except:\n",
    "        return embedding['unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2515686 word vectors.\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "#Load Word Embedding (Pub Med W2V)\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_model = KeyedVectors.load_word2vec_format(EMB_FILE, binary=True)\n",
    "print('Found %s word vectors.' % len(word_model.index2word))\n",
    "print(word_model['Cholera'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00481831,  0.13864845, -0.0831728 , -0.00180067, -0.00696073,\n",
       "       -0.02875327,  0.06748949,  0.081326  ,  0.11438117,  0.00530638,\n",
       "       -0.05866855,  0.05307228, -0.09064269,  0.03729252, -0.00409504,\n",
       "        0.02162931,  0.11918882, -0.05017674,  0.03869108,  0.12593974,\n",
       "       -0.06599744,  0.13589439,  0.02106961, -0.02205387,  0.04005024,\n",
       "        0.11348598, -0.09267536, -0.04086379, -0.07475508,  0.02114647,\n",
       "        0.03469999,  0.02900406,  0.06926779,  0.11697073, -0.01642677,\n",
       "       -0.00433   ,  0.06071504, -0.1460445 , -0.01645673, -0.0205683 ,\n",
       "        0.01536769,  0.0160432 , -0.00429431,  0.03412509, -0.05015106,\n",
       "        0.0433115 ,  0.08293187,  0.14879459, -0.0841924 , -0.06157425,\n",
       "       -0.02435092, -0.05808348, -0.11018413,  0.01283847, -0.07155055,\n",
       "        0.08904947, -0.0320092 , -0.11904893, -0.01103841,  0.11339661,\n",
       "        0.01087772, -0.05354536,  0.0755807 ,  0.07982337,  0.11575826,\n",
       "       -0.1831625 ,  0.01570357, -0.05355467,  0.065675  , -0.05932967,\n",
       "       -0.03676661, -0.07462332,  0.00044577,  0.00153271, -0.03720127,\n",
       "        0.01145657, -0.08598395,  0.05766727,  0.04346594,  0.02472698,\n",
       "       -0.00632352,  0.07478109, -0.14751568,  0.00042276,  0.07153147,\n",
       "       -0.04317615,  0.05340288, -0.05415744, -0.03303893, -0.00801888,\n",
       "        0.1599695 ,  0.12767492, -0.13511537,  0.03035033, -0.13292313,\n",
       "        0.08539953, -0.0836237 , -0.05180331,  0.06054433,  0.03975708,\n",
       "        0.01670674,  0.03159624, -0.01788864, -0.06639411, -0.05593725,\n",
       "        0.09114383,  0.04756305,  0.04932161,  0.03004119,  0.07016169,\n",
       "       -0.02260194, -0.04556023,  0.03894595,  0.01217773, -0.00601322,\n",
       "        0.05797451, -0.00971887,  0.05746256, -0.13967408,  0.01086034,\n",
       "        0.10084245,  0.03624213, -0.06944687,  0.0685041 , -0.04885901,\n",
       "        0.04780302, -0.00679059,  0.01222236,  0.00437053,  0.07078601,\n",
       "        0.01699295, -0.07954331,  0.00767401, -0.0145664 , -0.11008999,\n",
       "       -0.11576639,  0.13548341,  0.01189198,  0.0143217 , -0.04274936,\n",
       "        0.05950304,  0.11588787, -0.09925151,  0.17723823,  0.04470263,\n",
       "        0.13840638,  0.00854758,  0.00529029, -0.05929139,  0.04006265,\n",
       "       -0.07867515,  0.15129918, -0.04075605, -0.10410006, -0.07819599,\n",
       "       -0.00415787, -0.01824111, -0.11058792, -0.02471245, -0.0675789 ,\n",
       "        0.02324502,  0.08978401, -0.00416532,  0.07376785, -0.09705666,\n",
       "        0.0305866 , -0.07622315,  0.07103782,  0.0640178 , -0.08612579,\n",
       "       -0.05328164, -0.08038139, -0.06606452, -0.02051584,  0.01632557,\n",
       "        0.00574587,  0.05618691, -0.00502494,  0.02578453, -0.17098409,\n",
       "        0.00823839,  0.03290304, -0.02339313,  0.01141564, -0.04751321,\n",
       "        0.01437956,  0.01086074,  0.05908064,  0.08819009, -0.01194189,\n",
       "        0.07416315,  0.0550346 ,  0.01837375, -0.03660027, -0.18669142,\n",
       "        0.02552837, -0.00789387,  0.08663259, -0.01817776, -0.02489405],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model['Cholera']/np.linalg.norm(word_model['Cholera'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICD File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6553, 2)\n",
      "\n",
      "     Code                                   Long Description\n",
      "0   4019                 Unspecified essential hypertension\n",
      "1   4280              Congestive heart failure, unspecified\n",
      "2  42731                                Atrial fibrillation\n",
      "3  41401  Coronary atherosclerosis of native coronary ar...\n",
      "4   5849                  Acute kidney failure, unspecified\n"
     ]
    }
   ],
   "source": [
    "ICD_desc_filename = ICD_DESC_FILENAME\n",
    "df_icd = pd.read_csv(ICD_desc_filename, encoding = 'latin1')\n",
    "\n",
    "df_icd = df_icd[['Code', 'Long Description']]\n",
    "\n",
    "print(df_icd.shape)\n",
    "\n",
    "print('\\n', df_icd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Long Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4019</td>\n",
       "      <td>unspecified essential hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4280</td>\n",
       "      <td>congestive heart failure unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42731</td>\n",
       "      <td>atrial fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41401</td>\n",
       "      <td>coronary atherosclerosis native coronary artery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5849</td>\n",
       "      <td>acute kidney failure unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                  Long Description\n",
       "0   4019                unspecified essential hypertension\n",
       "1   4280              congestive heart failure unspecified\n",
       "2  42731                               atrial fibrillation\n",
       "3  41401   coronary atherosclerosis native coronary artery\n",
       "4   5849                  acute kidney failure unspecified"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_icd_cleaned = df_icd\n",
    "\n",
    "#Delete df_icd\n",
    "del df_icd\n",
    "\n",
    "def clean_icd(x):\n",
    "    sent = x\n",
    "    sent_tokenized = word_tokenize(sent)\n",
    "    \n",
    "    clean_sent = ''\n",
    "    \n",
    "    for token in sent_tokenized:\n",
    "        if token.lower() not in punc and token.lower() not in stop_words:\n",
    "            clean_sent = clean_sent + ' ' + token.lower()\n",
    "    \n",
    "    x = clean_sent\n",
    "    \n",
    "    del clean_sent\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "df_icd_cleaned['Long Description'] = df_icd_cleaned.apply(lambda x: clean_icd(x['Long Description']), axis = 1)\n",
    "\n",
    "df_icd_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture the ICD embedding as a numpy matrix\n",
    "#icd_sent_emb = df_icd_cleaned['Sentence Embedding'][:]\n",
    "#icd_sent_emb_list = [x for x in icd_sent_emb]\n",
    "\n",
    "#icd_sent_emb_matrix = np.asarray(icd_sent_emb_list, dtype=np.float32)\n",
    "#icd_sent_emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2833 2833 2833\n",
      "ICD_Sentences =  2833\n"
     ]
    }
   ],
   "source": [
    "icd_sentences = list(df_icd_cleaned.head(NUM_ICD_CODES)['Long Description']) # Number of sentences\n",
    "icd_codes = list(df_icd_cleaned.head(NUM_ICD_CODES)['Code'])\n",
    "icd_index = list(range(NUM_ICD_CODES))\n",
    "\n",
    "print(len(icd_sentences), len(icd_codes), len(icd_index))\n",
    "print(\"ICD_Sentences = \", len(icd_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Dictionary of ICD index, ICD Code and ICD desc\n",
    "\n",
    "# index, codes\n",
    "dict_index_code = dict(zip(icd_index, icd_codes))\n",
    "\n",
    "# codes, index\n",
    "dict_code_index = dict(zip(icd_codes, icd_index))\n",
    "\n",
    "#index, code desc\n",
    "dict_index_desc = dict(zip(icd_index, icd_sentences))\n",
    "\n",
    "#icd sentence embedding matrix slice\n",
    "#icd_sent_emb_matrix = icd_sent_emb_matrix[:NUM_ICD_CODES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned MIMIC-III DD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>top_ICD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{Admission Date:  [**2117-9-11**]             ...</td>\n",
       "      <td>100001.0</td>\n",
       "      <td>['25013', '3371', '5849', '5780', 'V5867', '25...</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "      <td>['25013', '3371', '5849', '5780', 'V5867', '25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{Admission Date:  [**2150-4-17**]             ...</td>\n",
       "      <td>100003.0</td>\n",
       "      <td>['53100', '2851', '07054', '5715', '45621', '5...</td>\n",
       "      <td>admission date discharge date of birth sex rec...</td>\n",
       "      <td>['53100', '2851', '5715', '45621', '53789', '4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{Admission Date:  [**2108-4-6**]       Dischar...</td>\n",
       "      <td>100006.0</td>\n",
       "      <td>['49320', '51881', '486', '20300', '2761', '78...</td>\n",
       "      <td>admission date discharge date of birth sex o c...</td>\n",
       "      <td>['49320', '51881', '486', '20300', '2761', '78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{Admission Date:  [**2145-3-31**]             ...</td>\n",
       "      <td>100007.0</td>\n",
       "      <td>['56081', '5570', '9973', '486', '4019']</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "      <td>['56081', '5570', '486', '4019']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{Admission Date:  [**2162-5-16**]             ...</td>\n",
       "      <td>100009.0</td>\n",
       "      <td>['41401', '99604', '4142', '25000', '27800', '...</td>\n",
       "      <td>admission date discharge date of birth sex kno...</td>\n",
       "      <td>['41401', '99604', '4142', '25000', '27800', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               TEXT   HADM_ID  \\\n",
       "0           0  {Admission Date:  [**2117-9-11**]             ...  100001.0   \n",
       "1           1  {Admission Date:  [**2150-4-17**]             ...  100003.0   \n",
       "2           2  {Admission Date:  [**2108-4-6**]       Dischar...  100006.0   \n",
       "3           3  {Admission Date:  [**2145-3-31**]             ...  100007.0   \n",
       "4           4  {Admission Date:  [**2162-5-16**]             ...  100009.0   \n",
       "\n",
       "                                           ICD9_CODE  \\\n",
       "0  ['25013', '3371', '5849', '5780', 'V5867', '25...   \n",
       "1  ['53100', '2851', '07054', '5715', '45621', '5...   \n",
       "2  ['49320', '51881', '486', '20300', '2761', '78...   \n",
       "3           ['56081', '5570', '9973', '486', '4019']   \n",
       "4  ['41401', '99604', '4142', '25000', '27800', '...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  admission date discharge date of birth sex nam...   \n",
       "1  admission date discharge date of birth sex rec...   \n",
       "2  admission date discharge date of birth sex o c...   \n",
       "3  admission date discharge date of birth sex nam...   \n",
       "4  admission date discharge date of birth sex kno...   \n",
       "\n",
       "                                             top_ICD  \n",
       "0  ['25013', '3371', '5849', '5780', 'V5867', '25...  \n",
       "1  ['53100', '2851', '5715', '45621', '53789', '4...  \n",
       "2  ['49320', '51881', '486', '20300', '2761', '78...  \n",
       "3                   ['56081', '5570', '486', '4019']  \n",
       "4  ['41401', '99604', '4142', '25000', '27800', '...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD_filename = DD_FILENAME\n",
    "df_DD = pd.read_csv(DD_filename)\n",
    "df_DD = df_DD[0:5000]\n",
    "df_DD.reset_index(drop=True, inplace= True)\n",
    "FILESIZE = df_DD.shape[0]\n",
    "df_DD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_boundary\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '...' or token.text == '.' or token.text =='!' :\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "custom_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "custom_nlp.add_pipe(\"custom_boundary\", before='parser')\n",
    "\n",
    "def removingNegativeSentence(text):\n",
    "    cleanText = []\n",
    "    negative_token = [\"not\",\"absence\",\"no\"]\n",
    "    custom_doc = custom_nlp(text)\n",
    "    custom_sentences = list(custom_doc.sents)\n",
    "    for sentence in custom_sentences:\n",
    "        #print (sentence.text)\n",
    "        flag  = False\n",
    "        for token in sentence:\n",
    "            #print (type(token))\n",
    "            if token.text in negative_token:\n",
    "                #Print the Dependant Word to Neg words\n",
    "                #print (token.text, token.tag_, token.head.text, token.dep_)\n",
    "                #displacy.serve(sentence, style='dep')\n",
    "                flag  = True\n",
    "                break\n",
    "        if(not flag):\n",
    "            #print(sentence.text)\n",
    "            cleanText.append(sentence.text)\n",
    "    return (' '.join(cleanText))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['25013', '3371', '5849', '5780', 'V5867', '25...</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['53100', '2851', '07054', '5715', '45621', '5...</td>\n",
       "      <td>admission date discharge date of birth sex rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['49320', '51881', '486', '20300', '2761', '78...</td>\n",
       "      <td>admission date discharge date of birth sex o c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['56081', '5570', '9973', '486', '4019']</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['41401', '99604', '4142', '25000', '27800', '...</td>\n",
       "      <td>admission date discharge date of birth sex kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>['5724', '5849', '07071', '7863', '5990', '456...</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>['30500', '2762', '28860', '4589']</td>\n",
       "      <td>admission date discharge date of birth sex on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>['41401', '3963', '39891', '3970', '42731', '9...</td>\n",
       "      <td>admission date discharge date of birth sex of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>['042', '11599', '4280', '2848', '7801', '2761...</td>\n",
       "      <td>admission date discharge date of birth sex com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>['80315', '4275', '8600', '5185', '5070', '305...</td>\n",
       "      <td>admission date discharge date of birth sex tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ICD9_CODE  \\\n",
       "0     ['25013', '3371', '5849', '5780', 'V5867', '25...   \n",
       "1     ['53100', '2851', '07054', '5715', '45621', '5...   \n",
       "2     ['49320', '51881', '486', '20300', '2761', '78...   \n",
       "3              ['56081', '5570', '9973', '486', '4019']   \n",
       "4     ['41401', '99604', '4142', '25000', '27800', '...   \n",
       "...                                                 ...   \n",
       "4995  ['5724', '5849', '07071', '7863', '5990', '456...   \n",
       "4996                 ['30500', '2762', '28860', '4589']   \n",
       "4997  ['41401', '3963', '39891', '3970', '42731', '9...   \n",
       "4998  ['042', '11599', '4280', '2848', '7801', '2761...   \n",
       "4999  ['80315', '4275', '8600', '5185', '5070', '305...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     admission date discharge date of birth sex nam...  \n",
       "1     admission date discharge date of birth sex rec...  \n",
       "2     admission date discharge date of birth sex o c...  \n",
       "3     admission date discharge date of birth sex nam...  \n",
       "4     admission date discharge date of birth sex kno...  \n",
       "...                                                 ...  \n",
       "4995  admission date discharge date of birth sex nam...  \n",
       "4996  admission date discharge date of birth sex on ...  \n",
       "4997  admission date discharge date of birth sex of ...  \n",
       "4998  admission date discharge date of birth sex com...  \n",
       "4999  admission date discharge date of birth sex tra...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DD_Data = df_DD[['ICD9_CODE', 'clean_text']]\n",
    "del df_DD\n",
    "DD_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['25013', '3371', '5849', '5780', 'V5867', '25...</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['53100', '2851', '07054', '5715', '45621', '5...</td>\n",
       "      <td>pt was in his until about days pta when he int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['49320', '51881', '486', '20300', '2761', '78...</td>\n",
       "      <td>admission date discharge date of birth sex o c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['56081', '5570', '9973', '486', '4019']</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['41401', '99604', '4142', '25000', '27800', '...</td>\n",
       "      <td>admission date discharge date of birth sex kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>['5724', '5849', '07071', '7863', '5990', '456...</td>\n",
       "      <td>admission date discharge date of birth sex nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>['30500', '2762', '28860', '4589']</td>\n",
       "      <td>admission date discharge date of birth sex on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>['41401', '3963', '39891', '3970', '42731', '9...</td>\n",
       "      <td>admission date discharge date of birth sex of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>['042', '11599', '4280', '2848', '7801', '2761...</td>\n",
       "      <td>admission date discharge date of birth sex com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>['80315', '4275', '8600', '5185', '5070', '305...</td>\n",
       "      <td>admission date discharge date of birth sex tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ICD9_CODE  \\\n",
       "0     ['25013', '3371', '5849', '5780', 'V5867', '25...   \n",
       "1     ['53100', '2851', '07054', '5715', '45621', '5...   \n",
       "2     ['49320', '51881', '486', '20300', '2761', '78...   \n",
       "3              ['56081', '5570', '9973', '486', '4019']   \n",
       "4     ['41401', '99604', '4142', '25000', '27800', '...   \n",
       "...                                                 ...   \n",
       "4995  ['5724', '5849', '07071', '7863', '5990', '456...   \n",
       "4996                 ['30500', '2762', '28860', '4589']   \n",
       "4997  ['41401', '3963', '39891', '3970', '42731', '9...   \n",
       "4998  ['042', '11599', '4280', '2848', '7801', '2761...   \n",
       "4999  ['80315', '4275', '8600', '5185', '5070', '305...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     admission date discharge date of birth sex nam...  \n",
       "1     pt was in his until about days pta when he int...  \n",
       "2     admission date discharge date of birth sex o c...  \n",
       "3     admission date discharge date of birth sex nam...  \n",
       "4     admission date discharge date of birth sex kno...  \n",
       "...                                                 ...  \n",
       "4995  admission date discharge date of birth sex nam...  \n",
       "4996  admission date discharge date of birth sex on ...  \n",
       "4997  admission date discharge date of birth sex of ...  \n",
       "4998  admission date discharge date of birth sex com...  \n",
       "4999  admission date discharge date of birth sex tra...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negation Removal\n",
    "DD_Data['clean_text'] = DD_Data['clean_text'].apply(lambda x: removingNegativeSentence(x))\n",
    "DD_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  26953\n",
      "Avg Doc Len:  1130.3818\n"
     ]
    }
   ],
   "source": [
    "Vocab = {}\n",
    "\n",
    "doc_len = []\n",
    "\n",
    "for index in range(DD_Data.shape[0]):\n",
    "    sent = word_tokenize(DD_Data['clean_text'][index])\n",
    "    \n",
    "    doc_len.append(len(sent))\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in Vocab.keys():\n",
    "            Vocab[word]+=1\n",
    "        else:\n",
    "            Vocab[word]=1\n",
    "\n",
    "print('Vocab Size: ', len(Vocab.keys()))\n",
    "print('Avg Doc Len: ', float(sum(doc_len))/float(len(doc_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Vocab, doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get TF vector using entire corpus\n",
    "def get_tf(docs):\n",
    "    \n",
    "    vectorizer = CountVectorizer()#CountVectorizer(stop_words = 'english')\n",
    "    X = vectorizer.fit_transform(docs)#(docs['sentence'])\n",
    "\n",
    "    # place tf values in a pandas data frame\n",
    "    tf_vecs = pd.DataFrame(X.T.todense(), index = vectorizer.get_feature_names())\n",
    "    \n",
    "    #Take sum accross sentences\n",
    "    freq_vec = tf_vecs.sum(axis = 1)\n",
    "    freq_vec = pd.DataFrame(freq_vec, index=freq_vec.index, columns=['Frequency'])\n",
    "    \n",
    "    return vectorizer, freq_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove terms not present in freq_vec\n",
    "def remove_unwanted_words(words, freq_vec):\n",
    "    \n",
    "    pruned_words = [x for x in words if x in freq_vec.index]\n",
    "    \n",
    "    #for i in words:\n",
    "    #    if i in freq_vec.index:\n",
    "    #        pruned_words.append(i)\n",
    "    \n",
    "    return list(set(pruned_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_vector(sent, freq_vec):\n",
    "    #tokenize sentence\n",
    "    words = list(set(word_tokenize(sent)))\n",
    "    \n",
    "    #remove terms not occuring in freq_vec\n",
    "    pruned_words = remove_unwanted_words(words, freq_vec)\n",
    "    \n",
    "    #get the slice of freq_vec using the remaining terms\n",
    "    #print(words, pruned_words)\n",
    "    freq_slice = freq_vec.loc[pruned_words, :]\n",
    "    \n",
    "    #L1 normalize to obtain tf vector\n",
    "    tf_vec = freq_slice/np.linalg.norm(freq_slice, ord = 1)    \n",
    "\n",
    "    return tf_vec, pruned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the cosine similarity matrix for 2 sentences\n",
    "def cosine_sim_matrix(s1, s2):\n",
    "    \n",
    "    #Get token-wise embedding\n",
    "    s1_token_emb = np.array([get_word_embedding(word, word_model) for word in s1])\n",
    "    #Normalize\n",
    "    s1_token_emb/=np.linalg.norm(s1_token_emb, axis = 1, ord = 2, keepdims=True)\n",
    "    \n",
    "    #Get token-wise embedding of icd text\n",
    "    s2_token_emb = np.array([get_word_embedding(word, word_model) for word in s2])\n",
    "    #Normalize\n",
    "    s2_token_emb/=np.linalg.norm(s2_token_emb, axis = 1, ord = 2, keepdims=True)\n",
    "    \n",
    "    \n",
    "    sim_matrix = s1_token_emb.dot(s2_token_emb.T)\n",
    "    \n",
    "    return np.clip(sim_matrix, -1.0, 1.0) #Clip the Elements of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Debugging Counter\n",
    "k = 0\n",
    "#Calculate the Similarity Score between 2 senteces\n",
    "def RWMS_similarity(sent_1, sent_2, freq_vec):\n",
    "    global k\n",
    "    try:\n",
    "        \n",
    "        #get tf vectors\n",
    "        #start = time.time()\n",
    "        sent1_tf_vec, sent1 = get_tf_vector(sent_1, freq_vec)\n",
    "        #sent2_tf_vec, sent2 = get_tf_vector(sent_2, freq_vec)\n",
    "        \n",
    "        #tokenized sentences\n",
    "        sent1 = sent1#list(set(word_tokenize(sent_1)))\n",
    "        sent2 = list(set(word_tokenize(sent_2)))\n",
    "\n",
    "        #Compute Cosine Similarity Matrix\n",
    "        sim_mat = cosine_sim_matrix(sent1, sent2)\n",
    "        #print('Sim_mat:\\n', sim_mat)\n",
    "        \n",
    "        #Initialise Similarity values:\n",
    "        W_s_t = 0\n",
    "        #W_t_s = 0\n",
    "\n",
    "        #for S->t (icd_text -> dd text)\n",
    "        max_cosine_vec = sim_mat.max(axis = 1)\n",
    "        #print('Sim_mat:\\n', sim_mat)\n",
    "        \n",
    "        # Take Elementwise product of max cos similarity vector and tf vector\n",
    "        sim_vec = sent1_tf_vec.to_numpy().transpose() * max_cosine_vec\n",
    "        \n",
    "        #Take sum of all elements of sim_vec to obtain final similarity\n",
    "        W_s_t = np.sum(sim_vec)\n",
    "        \n",
    "        del sim_mat, sent1_tf_vec, sent1, sent2\n",
    "        \n",
    "        #for t->S\n",
    "        #for j in range(len(sent2)):\n",
    "        #    w2 = sent2[j]\n",
    "        #    sim = 0\n",
    "        #    if w2 in density_tfidf.index:\n",
    "        #        #index of word with max cosine similarity from sent1\n",
    "        #        max_j = np.argmax(sim_mat.transpose()[j])\n",
    "\n",
    "        #        #multiply the tfidf value of current word of sent2 with cosine similarity of the most similar from sent1\n",
    "        #        sim = sim_mat.transpose()[j][max_j]*density_tfidf['s2_tfidf'][w2]\n",
    "        #    else:\n",
    "        #        sim = 0\n",
    "        #    W_t_s+=sim\n",
    "        \n",
    "        \n",
    "        #k = k + 1\n",
    "        #print('k: ', k)\n",
    "\n",
    "        return W_s_t#, sim_mat, max_cosine_vec, sent1_tf_vec, sent1, sent2   #min(W_s_t, W_t_s)\n",
    "    except:\n",
    "        #print('sent_1: ', sent_1)\n",
    "        sent_1_emb = get_sentence_embedding(sent1, word_model)\n",
    "        #print('sent_2: ', sent_2)\n",
    "        sent_2_emb = get_sentence_embedding(sent2, word_model)\n",
    "        \n",
    "        #k = k + 1\n",
    "        #print('k: ', k)\n",
    "        \n",
    "        return sent_1_emb.dot(sent_2_emb.T)#, 0, 0, 0, 0, 0#cosine_sim(sent_1_emb, sent_2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert ICD Indices to hot vectors of length: NUM_ICD_CODE\n",
    "def generate_binary(icd_index_list, total_icd = NUM_ICD_CODES):\n",
    "    binary_icd = np.zeros(total_icd)\n",
    "    for x in icd_index_list:\n",
    "        binary_icd[x] = 1\n",
    "        \n",
    "    return binary_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Specificity\n",
    "\n",
    "def calc_specificity(pred_vec, act_vec):\n",
    "    m = len(pred_vec)\n",
    "    \n",
    "    specificity = []\n",
    "    \n",
    "    for i in range(m):\n",
    "        pred, act = pred_vec[i], act_vec[i]\n",
    "        dict_XY = {'pred':pred, 'act':act}\n",
    "        res = pd.DataFrame(dict_XY, columns=['pred', 'act'])\n",
    "        res['Sum'] = res['pred'] + res['act']\n",
    "        \n",
    "        pred_p = res[res.pred == 1]\n",
    "        pred_n = res[res.act == 1]\n",
    "        \n",
    "        tp = len(res[res.Sum == 2])\n",
    "        tn = len(res[res.Sum == 0]) \n",
    "        \n",
    "        fp = len(pred_p[pred_p.act == 0])\n",
    "        fn = len(pred_n[pred_n.act == 1])\n",
    "        \n",
    "        #Calculate specificity for this example:\n",
    "        spec = tn/(tn + fp)\n",
    "        \n",
    "        specificity.append(spec)\n",
    "    \n",
    "    return sum(specificity) / float(m)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/5000 records done.\n",
      "20/5000 records done.\n",
      "30/5000 records done.\n",
      "40/5000 records done.\n",
      "50/5000 records done.\n",
      "60/5000 records done.\n",
      "70/5000 records done.\n",
      "80/5000 records done.\n",
      "90/5000 records done.\n",
      "100/5000 records done.\n",
      "\n",
      "Time elapsed:  67.83916195233662  minutes\n",
      "110/5000 records done.\n",
      "120/5000 records done.\n",
      "130/5000 records done.\n",
      "140/5000 records done.\n",
      "150/5000 records done.\n",
      "160/5000 records done.\n",
      "170/5000 records done.\n",
      "180/5000 records done.\n",
      "190/5000 records done.\n",
      "200/5000 records done.\n",
      "\n",
      "Time elapsed:  142.82773968378703  minutes\n",
      "210/5000 records done.\n",
      "220/5000 records done.\n",
      "230/5000 records done.\n",
      "240/5000 records done.\n",
      "250/5000 records done.\n",
      "260/5000 records done.\n",
      "270/5000 records done.\n",
      "280/5000 records done.\n",
      "290/5000 records done.\n",
      "300/5000 records done.\n",
      "\n",
      "Time elapsed:  213.87786363363267  minutes\n",
      "310/5000 records done.\n",
      "320/5000 records done.\n",
      "330/5000 records done.\n",
      "340/5000 records done.\n",
      "350/5000 records done.\n",
      "360/5000 records done.\n",
      "370/5000 records done.\n",
      "380/5000 records done.\n",
      "390/5000 records done.\n",
      "400/5000 records done.\n",
      "\n",
      "Time elapsed:  275.7376577695211  minutes\n",
      "410/5000 records done.\n",
      "420/5000 records done.\n",
      "430/5000 records done.\n",
      "440/5000 records done.\n",
      "450/5000 records done.\n",
      "460/5000 records done.\n",
      "470/5000 records done.\n",
      "480/5000 records done.\n",
      "490/5000 records done.\n",
      "500/5000 records done.\n",
      "\n",
      "Time elapsed:  348.82426828543345  minutes\n",
      "510/5000 records done.\n",
      "520/5000 records done.\n",
      "530/5000 records done.\n",
      "540/5000 records done.\n",
      "550/5000 records done.\n",
      "560/5000 records done.\n",
      "570/5000 records done.\n",
      "580/5000 records done.\n",
      "590/5000 records done.\n",
      "600/5000 records done.\n",
      "\n",
      "Time elapsed:  421.04670923550924  minutes\n",
      "610/5000 records done.\n",
      "620/5000 records done.\n",
      "630/5000 records done.\n",
      "640/5000 records done.\n",
      "650/5000 records done.\n",
      "660/5000 records done.\n",
      "670/5000 records done.\n",
      "680/5000 records done.\n",
      "690/5000 records done.\n",
      "700/5000 records done.\n",
      "\n",
      "Time elapsed:  504.94494646787643  minutes\n",
      "710/5000 records done.\n",
      "720/5000 records done.\n",
      "730/5000 records done.\n",
      "740/5000 records done.\n",
      "750/5000 records done.\n",
      "760/5000 records done.\n",
      "770/5000 records done.\n",
      "780/5000 records done.\n",
      "790/5000 records done.\n",
      "800/5000 records done.\n",
      "\n",
      "Time elapsed:  575.9238458156585  minutes\n",
      "810/5000 records done.\n",
      "820/5000 records done.\n",
      "830/5000 records done.\n",
      "840/5000 records done.\n",
      "850/5000 records done.\n",
      "860/5000 records done.\n",
      "870/5000 records done.\n",
      "880/5000 records done.\n",
      "890/5000 records done.\n",
      "900/5000 records done.\n",
      "\n",
      "Time elapsed:  641.1878667990367  minutes\n",
      "910/5000 records done.\n",
      "920/5000 records done.\n",
      "930/5000 records done.\n",
      "940/5000 records done.\n",
      "950/5000 records done.\n",
      "960/5000 records done.\n",
      "970/5000 records done.\n",
      "980/5000 records done.\n",
      "990/5000 records done.\n",
      "1000/5000 records done.\n",
      "\n",
      "Time elapsed:  721.9367815375329  minutes\n",
      "1010/5000 records done.\n",
      "1020/5000 records done.\n",
      "1030/5000 records done.\n",
      "1040/5000 records done.\n",
      "1050/5000 records done.\n",
      "1060/5000 records done.\n",
      "1070/5000 records done.\n",
      "1080/5000 records done.\n",
      "1090/5000 records done.\n",
      "1100/5000 records done.\n",
      "\n",
      "Time elapsed:  787.2537678201993  minutes\n",
      "1110/5000 records done.\n",
      "1120/5000 records done.\n",
      "1130/5000 records done.\n",
      "1140/5000 records done.\n",
      "1150/5000 records done.\n",
      "1160/5000 records done.\n",
      "1170/5000 records done.\n",
      "1180/5000 records done.\n",
      "1190/5000 records done.\n",
      "1200/5000 records done.\n",
      "\n",
      "Time elapsed:  864.3691100517909  minutes\n",
      "1210/5000 records done.\n",
      "1220/5000 records done.\n",
      "1230/5000 records done.\n",
      "1240/5000 records done.\n",
      "1250/5000 records done.\n",
      "1260/5000 records done.\n",
      "1270/5000 records done.\n",
      "1280/5000 records done.\n",
      "1290/5000 records done.\n",
      "1300/5000 records done.\n",
      "\n",
      "Time elapsed:  945.9094227671624  minutes\n",
      "1310/5000 records done.\n",
      "1320/5000 records done.\n",
      "1330/5000 records done.\n",
      "1340/5000 records done.\n",
      "1350/5000 records done.\n",
      "1360/5000 records done.\n",
      "1370/5000 records done.\n",
      "1380/5000 records done.\n",
      "1390/5000 records done.\n",
      "1400/5000 records done.\n",
      "\n",
      "Time elapsed:  1025.858493789037  minutes\n",
      "1410/5000 records done.\n",
      "1420/5000 records done.\n",
      "1430/5000 records done.\n",
      "1440/5000 records done.\n",
      "1450/5000 records done.\n",
      "1460/5000 records done.\n",
      "1470/5000 records done.\n",
      "1480/5000 records done.\n",
      "1490/5000 records done.\n",
      "1500/5000 records done.\n",
      "\n",
      "Time elapsed:  1091.3878590544066  minutes\n",
      "1510/5000 records done.\n",
      "1520/5000 records done.\n",
      "1530/5000 records done.\n",
      "1540/5000 records done.\n",
      "1550/5000 records done.\n",
      "1560/5000 records done.\n",
      "1570/5000 records done.\n",
      "1580/5000 records done.\n",
      "1590/5000 records done.\n",
      "1600/5000 records done.\n",
      "\n",
      "Time elapsed:  1158.281971136729  minutes\n",
      "1610/5000 records done.\n",
      "1620/5000 records done.\n",
      "1630/5000 records done.\n",
      "1640/5000 records done.\n",
      "1650/5000 records done.\n",
      "1660/5000 records done.\n",
      "1670/5000 records done.\n",
      "1680/5000 records done.\n",
      "1690/5000 records done.\n",
      "1700/5000 records done.\n",
      "\n",
      "Time elapsed:  1227.3063343365986  minutes\n",
      "1710/5000 records done.\n",
      "1720/5000 records done.\n",
      "1730/5000 records done.\n",
      "1740/5000 records done.\n",
      "1750/5000 records done.\n",
      "1760/5000 records done.\n",
      "1770/5000 records done.\n",
      "1780/5000 records done.\n",
      "1790/5000 records done.\n",
      "1800/5000 records done.\n",
      "\n",
      "Time elapsed:  1298.3430545051892  minutes\n",
      "1810/5000 records done.\n",
      "1820/5000 records done.\n",
      "1830/5000 records done.\n",
      "1840/5000 records done.\n",
      "1850/5000 records done.\n",
      "1860/5000 records done.\n",
      "1870/5000 records done.\n",
      "1880/5000 records done.\n",
      "1890/5000 records done.\n",
      "1900/5000 records done.\n",
      "\n",
      "Time elapsed:  1368.1946646531424  minutes\n",
      "1910/5000 records done.\n",
      "1920/5000 records done.\n",
      "1930/5000 records done.\n",
      "1940/5000 records done.\n",
      "1950/5000 records done.\n",
      "1960/5000 records done.\n",
      "1970/5000 records done.\n",
      "1980/5000 records done.\n",
      "1990/5000 records done.\n",
      "2000/5000 records done.\n",
      "\n",
      "Time elapsed:  1435.5104632059733  minutes\n",
      "2010/5000 records done.\n",
      "2020/5000 records done.\n",
      "2030/5000 records done.\n",
      "2040/5000 records done.\n",
      "2050/5000 records done.\n",
      "2060/5000 records done.\n",
      "2070/5000 records done.\n",
      "2080/5000 records done.\n",
      "2090/5000 records done.\n",
      "2100/5000 records done.\n",
      "\n",
      "Time elapsed:  1515.6276818871497  minutes\n",
      "2110/5000 records done.\n",
      "2120/5000 records done.\n",
      "2130/5000 records done.\n",
      "2140/5000 records done.\n",
      "2150/5000 records done.\n",
      "2160/5000 records done.\n",
      "2170/5000 records done.\n",
      "2180/5000 records done.\n",
      "2190/5000 records done.\n",
      "2200/5000 records done.\n",
      "\n",
      "Time elapsed:  1595.2444998224576  minutes\n",
      "2210/5000 records done.\n",
      "2220/5000 records done.\n",
      "2230/5000 records done.\n",
      "2240/5000 records done.\n",
      "2250/5000 records done.\n",
      "2260/5000 records done.\n",
      "2270/5000 records done.\n",
      "2280/5000 records done.\n",
      "2290/5000 records done.\n",
      "2300/5000 records done.\n",
      "\n",
      "Time elapsed:  1661.2418862024942  minutes\n",
      "2310/5000 records done.\n",
      "2320/5000 records done.\n",
      "2330/5000 records done.\n",
      "2340/5000 records done.\n",
      "2350/5000 records done.\n",
      "2360/5000 records done.\n",
      "2370/5000 records done.\n",
      "2380/5000 records done.\n",
      "2390/5000 records done.\n",
      "2400/5000 records done.\n",
      "\n",
      "Time elapsed:  1726.705357269446  minutes\n",
      "2410/5000 records done.\n",
      "2420/5000 records done.\n",
      "2430/5000 records done.\n",
      "2440/5000 records done.\n",
      "2450/5000 records done.\n",
      "2460/5000 records done.\n",
      "2470/5000 records done.\n",
      "2480/5000 records done.\n",
      "2490/5000 records done.\n",
      "2500/5000 records done.\n",
      "\n",
      "Time elapsed:  1799.444968700409  minutes\n",
      "2510/5000 records done.\n",
      "2520/5000 records done.\n",
      "2530/5000 records done.\n",
      "2540/5000 records done.\n",
      "2550/5000 records done.\n",
      "2560/5000 records done.\n",
      "2570/5000 records done.\n",
      "2580/5000 records done.\n",
      "2590/5000 records done.\n",
      "2600/5000 records done.\n",
      "\n",
      "Time elapsed:  1873.704789551099  minutes\n",
      "2610/5000 records done.\n",
      "2620/5000 records done.\n",
      "2630/5000 records done.\n",
      "2640/5000 records done.\n",
      "2650/5000 records done.\n",
      "2660/5000 records done.\n",
      "2670/5000 records done.\n",
      "2680/5000 records done.\n",
      "2690/5000 records done.\n",
      "2700/5000 records done.\n",
      "\n",
      "Time elapsed:  1939.8404410044352  minutes\n",
      "2710/5000 records done.\n",
      "2720/5000 records done.\n",
      "2730/5000 records done.\n",
      "2740/5000 records done.\n",
      "2750/5000 records done.\n",
      "2760/5000 records done.\n",
      "2770/5000 records done.\n",
      "2780/5000 records done.\n",
      "2790/5000 records done.\n",
      "2800/5000 records done.\n",
      "\n",
      "Time elapsed:  2016.578424167633  minutes\n",
      "2810/5000 records done.\n",
      "2820/5000 records done.\n",
      "2830/5000 records done.\n",
      "2840/5000 records done.\n",
      "2850/5000 records done.\n",
      "2860/5000 records done.\n",
      "2870/5000 records done.\n",
      "2880/5000 records done.\n",
      "2890/5000 records done.\n",
      "2900/5000 records done.\n",
      "\n",
      "Time elapsed:  2085.6336268703144  minutes\n",
      "2910/5000 records done.\n",
      "2920/5000 records done.\n",
      "2930/5000 records done.\n",
      "2940/5000 records done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/5000 records done.\n",
      "2960/5000 records done.\n",
      "2970/5000 records done.\n",
      "2980/5000 records done.\n",
      "2990/5000 records done.\n",
      "3000/5000 records done.\n",
      "\n",
      "Time elapsed:  2181.7674114545184  minutes\n",
      "3010/5000 records done.\n",
      "3020/5000 records done.\n",
      "3030/5000 records done.\n",
      "3040/5000 records done.\n",
      "3050/5000 records done.\n",
      "3060/5000 records done.\n",
      "3070/5000 records done.\n",
      "3080/5000 records done.\n",
      "3090/5000 records done.\n",
      "3100/5000 records done.\n",
      "\n",
      "Time elapsed:  2246.06022768418  minutes\n",
      "3110/5000 records done.\n",
      "3120/5000 records done.\n",
      "3130/5000 records done.\n",
      "3140/5000 records done.\n",
      "3150/5000 records done.\n",
      "3160/5000 records done.\n",
      "3170/5000 records done.\n",
      "3180/5000 records done.\n",
      "3190/5000 records done.\n",
      "3200/5000 records done.\n",
      "\n",
      "Time elapsed:  2312.5769924998285  minutes\n",
      "3210/5000 records done.\n",
      "3220/5000 records done.\n",
      "3230/5000 records done.\n",
      "3240/5000 records done.\n",
      "3250/5000 records done.\n",
      "3260/5000 records done.\n",
      "3270/5000 records done.\n",
      "3280/5000 records done.\n",
      "3290/5000 records done.\n",
      "3300/5000 records done.\n",
      "\n",
      "Time elapsed:  2379.6841370344164  minutes\n",
      "3310/5000 records done.\n",
      "3320/5000 records done.\n",
      "3330/5000 records done.\n",
      "3340/5000 records done.\n",
      "3350/5000 records done.\n",
      "3360/5000 records done.\n",
      "3370/5000 records done.\n",
      "3380/5000 records done.\n",
      "3390/5000 records done.\n",
      "3400/5000 records done.\n",
      "\n",
      "Time elapsed:  2443.622135555744  minutes\n",
      "3410/5000 records done.\n",
      "3420/5000 records done.\n",
      "3430/5000 records done.\n",
      "3440/5000 records done.\n",
      "3450/5000 records done.\n",
      "3460/5000 records done.\n",
      "3470/5000 records done.\n",
      "3480/5000 records done.\n",
      "3490/5000 records done.\n",
      "3500/5000 records done.\n",
      "\n",
      "Time elapsed:  2506.175837568442  minutes\n",
      "3510/5000 records done.\n",
      "3520/5000 records done.\n",
      "3530/5000 records done.\n",
      "3540/5000 records done.\n",
      "3550/5000 records done.\n",
      "3560/5000 records done.\n",
      "3570/5000 records done.\n",
      "3580/5000 records done.\n",
      "3590/5000 records done.\n",
      "3600/5000 records done.\n",
      "\n",
      "Time elapsed:  2572.9956508517266  minutes\n",
      "3610/5000 records done.\n",
      "3620/5000 records done.\n",
      "3630/5000 records done.\n",
      "3640/5000 records done.\n",
      "3650/5000 records done.\n",
      "3660/5000 records done.\n",
      "3670/5000 records done.\n",
      "3680/5000 records done.\n",
      "3690/5000 records done.\n",
      "3700/5000 records done.\n",
      "\n",
      "Time elapsed:  2636.950746667385  minutes\n",
      "3710/5000 records done.\n",
      "3720/5000 records done.\n",
      "3730/5000 records done.\n",
      "3740/5000 records done.\n",
      "3750/5000 records done.\n",
      "3760/5000 records done.\n",
      "3770/5000 records done.\n",
      "3780/5000 records done.\n",
      "3790/5000 records done.\n",
      "3800/5000 records done.\n",
      "\n",
      "Time elapsed:  2712.0870244542757  minutes\n",
      "3810/5000 records done.\n",
      "3820/5000 records done.\n",
      "3830/5000 records done.\n",
      "3840/5000 records done.\n",
      "3850/5000 records done.\n",
      "3860/5000 records done.\n",
      "3870/5000 records done.\n",
      "3880/5000 records done.\n",
      "3890/5000 records done.\n",
      "3900/5000 records done.\n",
      "\n",
      "Time elapsed:  2789.413584971428  minutes\n",
      "3910/5000 records done.\n",
      "3920/5000 records done.\n",
      "3930/5000 records done.\n",
      "3940/5000 records done.\n",
      "3950/5000 records done.\n",
      "3960/5000 records done.\n",
      "3970/5000 records done.\n",
      "3980/5000 records done.\n",
      "3990/5000 records done.\n",
      "4000/5000 records done.\n",
      "\n",
      "Time elapsed:  2852.728672285875  minutes\n",
      "4010/5000 records done.\n",
      "4020/5000 records done.\n",
      "4030/5000 records done.\n",
      "4040/5000 records done.\n",
      "4050/5000 records done.\n",
      "4060/5000 records done.\n",
      "4070/5000 records done.\n",
      "4080/5000 records done.\n",
      "4090/5000 records done.\n",
      "4100/5000 records done.\n",
      "\n",
      "Time elapsed:  2916.5648780028027  minutes\n",
      "4110/5000 records done.\n",
      "4120/5000 records done.\n",
      "4130/5000 records done.\n",
      "4140/5000 records done.\n",
      "4150/5000 records done.\n",
      "4160/5000 records done.\n",
      "4170/5000 records done.\n",
      "4180/5000 records done.\n",
      "4190/5000 records done.\n",
      "4200/5000 records done.\n",
      "\n",
      "Time elapsed:  2985.022305337588  minutes\n",
      "4210/5000 records done.\n",
      "4220/5000 records done.\n",
      "4230/5000 records done.\n",
      "4240/5000 records done.\n",
      "4250/5000 records done.\n",
      "4260/5000 records done.\n",
      "4270/5000 records done.\n",
      "4280/5000 records done.\n",
      "4290/5000 records done.\n",
      "4300/5000 records done.\n",
      "\n",
      "Time elapsed:  4579.441413319111  minutes\n",
      "4310/5000 records done.\n",
      "4320/5000 records done.\n",
      "4330/5000 records done.\n",
      "4340/5000 records done.\n",
      "4350/5000 records done.\n",
      "4360/5000 records done.\n",
      "4370/5000 records done.\n",
      "4380/5000 records done.\n",
      "4390/5000 records done.\n",
      "4400/5000 records done.\n",
      "\n",
      "Time elapsed:  4638.687770219644  minutes\n",
      "4410/5000 records done.\n",
      "4420/5000 records done.\n",
      "4430/5000 records done.\n",
      "4440/5000 records done.\n",
      "4450/5000 records done.\n",
      "4460/5000 records done.\n",
      "4470/5000 records done.\n",
      "4480/5000 records done.\n",
      "4490/5000 records done.\n",
      "4500/5000 records done.\n",
      "\n",
      "Time elapsed:  4698.020257584254  minutes\n",
      "4510/5000 records done.\n",
      "4520/5000 records done.\n",
      "4530/5000 records done.\n",
      "4540/5000 records done.\n",
      "4550/5000 records done.\n",
      "4560/5000 records done.\n",
      "4570/5000 records done.\n",
      "4580/5000 records done.\n",
      "4590/5000 records done.\n",
      "4600/5000 records done.\n",
      "\n",
      "Time elapsed:  4759.938746786118  minutes\n",
      "4610/5000 records done.\n",
      "4620/5000 records done.\n",
      "4630/5000 records done.\n",
      "4640/5000 records done.\n",
      "4650/5000 records done.\n",
      "4660/5000 records done.\n",
      "4670/5000 records done.\n",
      "4680/5000 records done.\n",
      "4690/5000 records done.\n",
      "4700/5000 records done.\n",
      "\n",
      "Time elapsed:  4819.002472519875  minutes\n",
      "4710/5000 records done.\n",
      "4720/5000 records done.\n",
      "4730/5000 records done.\n",
      "4740/5000 records done.\n",
      "4750/5000 records done.\n",
      "4760/5000 records done.\n",
      "4770/5000 records done.\n",
      "4780/5000 records done.\n",
      "4790/5000 records done.\n",
      "4800/5000 records done.\n",
      "\n",
      "Time elapsed:  4882.63106858333  minutes\n",
      "4810/5000 records done.\n",
      "4820/5000 records done.\n",
      "4830/5000 records done.\n",
      "4840/5000 records done.\n",
      "4850/5000 records done.\n",
      "4860/5000 records done.\n",
      "4870/5000 records done.\n",
      "4880/5000 records done.\n",
      "4890/5000 records done.\n",
      "4900/5000 records done.\n",
      "\n",
      "Time elapsed:  4945.724881005287  minutes\n",
      "4910/5000 records done.\n",
      "4920/5000 records done.\n",
      "4930/5000 records done.\n",
      "4940/5000 records done.\n",
      "4950/5000 records done.\n",
      "4960/5000 records done.\n",
      "4970/5000 records done.\n",
      "4980/5000 records done.\n",
      "4990/5000 records done.\n",
      "5000/5000 records done.\n",
      "\n",
      "Time elapsed:  5006.887632803122  minutes\n",
      "\n",
      "Time elapsed:  5007.269189703465  minutes\n",
      "Saving Similarity scores in file......\n",
      "Similarity Scores Saved!\n"
     ]
    }
   ],
   "source": [
    "#Predict ICD 9 Codes\n",
    "\n",
    "#construct the Term Frequency Vector using just the icd corpus\n",
    "c_vectorizer, freq_vec = get_tf(df_icd_cleaned['Long Description'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Calculate the Similarity of each document with each icd text\n",
    "X = DD_Data['clean_text']#[0]\n",
    "Y = list(DD_Data['ICD9_CODE'])\n",
    "m = len(Y)\n",
    "\n",
    "sim = []\n",
    "\n",
    "for i in range(m):\n",
    "    text = X[i]\n",
    "    #Modified#Calculate cosine similarity of sentence with icd sentences\n",
    "    sim.append(np.array([RWMS_similarity(icd_text, text, freq_vec) for icd_text in icd_sentences]))#cosine_sim1_matrix(sent_emb)\n",
    "    \n",
    "    #reset debugging counter\n",
    "    #global k\n",
    "    #k = 0\n",
    "    \n",
    "    if (i+1)%10 == 0:\n",
    "        print(str(i+1) + '/' + str(m) + ' records done.')\n",
    "    \n",
    "    if (i+1)%100 == 0:\n",
    "        print('\\nTime elapsed: ', (time.time() - start_time)/60.0, ' minutes')\n",
    "\n",
    "    if (i+1)%1000 == 0:\n",
    "        sim_df = pd.DataFrame(sim, dtype = float)\n",
    "        sim_df.to_csv('Similarity_Data/Optimized_NP_RWMS_Negation_similarity_data_' + str(i+1) + '_records.csv')\n",
    "        #sim_df.to_csv('Optimized_NP_RWMS_similarity_data_' + (i+1) + '_records.csv')\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print('\\nTime elapsed: ', time_elapsed/60.0, ' minutes')\n",
    "\n",
    "#Save the similarity scores in an excel file\n",
    "print('Saving Similarity scores in file......')\n",
    "sim_df = pd.DataFrame(sim, dtype = float)\n",
    "sim_df.to_csv('Similarity_Data/Optimized_NP_RWMS_Negation_similarity_data_' + str(m) + '_records.csv')\n",
    "#sim_df.to_csv('Optimized_NP_RWMS_similarity_data_' + str(m) + '_records.csv')\n",
    "print('Similarity Scores Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Similarity Data\n",
    "sim = pd.read_csv('Similarity_Data/Optimized_NP_RWMS_Negation_similarity_data_' + str(m) + '_records.csv')\n",
    "#sim = pd.read_csv('Optimized_NP_RWMS_similarity_data_' + str(m) + '_records.csv')\n",
    "\n",
    "#Drop first column\n",
    "sim = sim.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "#Convert DataFrame to List\n",
    "sim = np.array(sim.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2833)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Commenced for Similarity Threshold: 0.6\n",
      "\n",
      "Commenced for Similarity Threshold: 0.7\n",
      "\n",
      "Commenced for Similarity Threshold: 0.8\n",
      "\n",
      "Commenced for Similarity Threshold: 0.9\n"
     ]
    }
   ],
   "source": [
    "#Save Predictions and Corresponding Scores per threshold\n",
    "\n",
    "#Initialise Similarity Result Dataframe\n",
    "results_sim = pd.DataFrame(columns = ['Actual Code', \n",
    "                                  'Predicted Codes',\n",
    "                                  'Similarity Codes'])\n",
    "\n",
    "\n",
    "threshold_list = [0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#Initialize Excel\n",
    "#writer = pd.ExcelWriter('Similarity_Data/Code and Similarity Data - Unsupervised ICD - ' + str(m) + ' Records.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for thresh in threshold_list:\n",
    "\n",
    "    #Print Threshold:\n",
    "    print('\\nCommenced for Similarity Threshold:', thresh)\n",
    "\n",
    "    #X = DD_Data['clean_text'][0]\n",
    "    #Y = list(DD_Data['ICD9_CODE'])\n",
    "\n",
    "    data_input_format = []\n",
    "\n",
    "    i = 0\n",
    "    for i in range(m):\n",
    "        #Convert Actual Codes to indices. Consider only those codes present in icd_codes\n",
    "        act_codes = [str(y) for y in Y[i][2:-2].split(\"', '\") if y in icd_codes]#To get rid of '' and ,\n",
    "        act_codes_string = ', '.join(act_codes)\n",
    "\n",
    "        #Apply thresholding to obtain indices of similar embeddings\n",
    "        #print(sim)\n",
    "        threshold_filter = sim[i] > thresh\n",
    "\n",
    "\n",
    "        #Similarity >= threshold --> similarity \n",
    "        #Similarity < threshold --> 0\n",
    "        sim_post_threshold = sim[i]*threshold_filter\n",
    "\n",
    "        #Add indices of non zero elements to pred\n",
    "        pred_indices = np.nonzero(sim_post_threshold)[0].tolist()\n",
    "\n",
    "        #Get codes from indices\n",
    "        pred_codes = [str(dict_index_code[p]) for p in pred_indices]\n",
    "        #Convert to Comma Separated String\n",
    "        pred_codes_string = ', '.join(pred_codes)\n",
    "        #print([pred_codes_string])\n",
    "\n",
    "        #Corresponding Similarity Scores of List of Indices\n",
    "        sim_scores = [str(sim[i][j]) for j in pred_indices]\n",
    "        #Convert to Comma Separated String\n",
    "        sim_scores_string = ', '.join(sim_scores)\n",
    "        #print([sim_scores_string])\n",
    "\n",
    "\n",
    "        data_input = [act_codes_string, pred_codes_string, sim_scores_string]\n",
    "\n",
    "        #Append\n",
    "        data_input_format.append(data_input)\n",
    "\n",
    "    df = pd.DataFrame(data_input_format, columns = ['Actual Codes', 'Predicted Codes', 'Similarity Scores'])\n",
    "    df.to_csv('Similarity_Data/Negation - Code and Similarity Data - Unsupervised ICD - ' + str(m) + ' Records_' + str(thresh) + '_threshold.csv')\n",
    "    #df.to_csv('NP - Predicted Codes and Similarity Data - Unsupervised ICD - ' + str(m) + ' Records_' + str(thresh) + '_threshold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Commenced for Similarity Threshold: 0.6\n",
      "\n",
      "Precision:  0.00584824536306984  Recall:  0.5570257311225797  F1-Score:  0.011574964504443624  Specificity: 0.633190276736831\n",
      "\n",
      "Commenced for Similarity Threshold: 0.7\n",
      "\n",
      "Precision:  0.008038848364757562  Recall:  0.40805607408220784  F1-Score:  0.01576707970659386  Specificity: 0.8049285307275535\n",
      "\n",
      "Commenced for Similarity Threshold: 0.8\n",
      "\n",
      "Precision:  0.011413698740507768  Recall:  0.2903627246440467  F1-Score:  0.021964026396700826  Specificity: 0.902557137789861\n",
      "\n",
      "Commenced for Similarity Threshold: 0.9\n",
      "\n",
      "Precision:  0.014884067005280848  Recall:  0.1918304600856484  F1-Score:  0.02762473892618776  Specificity: 0.9508049671668832\n",
      "\n",
      "Time elapsed:  1.4645623167355855  minutes\n",
      "Results Saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Observations</th>\n",
       "      <th>Number of ICD Codes</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.557026</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.633190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.408056</td>\n",
       "      <td>0.015767</td>\n",
       "      <td>0.804929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.290363</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>0.902557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.191830</td>\n",
       "      <td>0.027625</td>\n",
       "      <td>0.950805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Observations  Number of ICD Codes  Threshold  Precision  \\\n",
       "0                  5000.0               2833.0        0.6   0.005848   \n",
       "1                  5000.0               2833.0        0.7   0.008039   \n",
       "2                  5000.0               2833.0        0.8   0.011414   \n",
       "3                  5000.0               2833.0        0.9   0.014884   \n",
       "\n",
       "     Recall  F1-Score  Specificity  \n",
       "0  0.557026  0.011575     0.633190  \n",
       "1  0.408056  0.015767     0.804929  \n",
       "2  0.290363  0.021964     0.902557  \n",
       "3  0.191830  0.027625     0.950805  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Metrics\n",
    "\n",
    "#Initialize Results Dataframe which will store the relevant metrics for each threshold\n",
    "results = pd.DataFrame(columns = ['Number of Observations', \n",
    "                                  'Number of ICD Codes',\n",
    "                                  'Threshold',\n",
    "                                  'Precision', \n",
    "                                  'Recall', \n",
    "                                  'F1-Score', \n",
    "                                  'Specificity'])\n",
    "\n",
    "#Compute Accuracy metrics based on thresholding        \n",
    "#threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#threshold_list = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "threshold_list = [0.6, 0.7, 0.8, 0.9]\n",
    "#threshold_list = [0.4]\n",
    "#threshold_list = [1.0, 5.0 10.0, 15.0, 20.0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for thresh in threshold_list:\n",
    "\n",
    "    #Print Threshold:\n",
    "    print('\\nCommenced for Similarity Threshold:', thresh)\n",
    "    \n",
    "    #X = DD_Data['clean_text'][0]\n",
    "    #Y = list(DD_Data['ICD9_CODE'])\n",
    "    \n",
    "    predicted_codes_index = []\n",
    "    actual_codes_index = []\n",
    "\n",
    "    #m = 1#len(Y)\n",
    "\n",
    "    for i in range(m):\n",
    "        #text = X#[i]\n",
    "        #print(i)\n",
    "        #Convert Actual Codes to indices. Consider only those codes present in icd_codes\n",
    "        act_icd_indices = [dict_code_index[y] for y in Y[i][2:-2].split(\"', '\") if y in icd_codes] #To get rid of '' and ,\n",
    "\n",
    "        #Initialize Prediction list. This will contain indices of similar icd codes\n",
    "        pred = []\n",
    "\n",
    "        #Apply thresholding to obtain indices of similar embeddings\n",
    "        #print(sim)\n",
    "        threshold_filter = sim[i] > thresh\n",
    "\n",
    "        \n",
    "        #Similarity >= threshold --> similarity \n",
    "        #Similarity < threshold --> 0\n",
    "        sim_post_threshold = sim[i]*threshold_filter\n",
    "\n",
    "        #Add indices of non zero elements to pred\n",
    "        pred.extend(np.nonzero(sim_post_threshold)[0].tolist())\n",
    "\n",
    "        #Consider the unique indices\n",
    "        pred = set(pred)\n",
    "\n",
    "        #Convert list of indices to hot vector\n",
    "        pred_icd_vector = generate_binary(pred)\n",
    "        act_icd_vector = generate_binary(act_icd_indices)\n",
    "\n",
    "        #Append\n",
    "        predicted_codes_index.append(pred_icd_vector)\n",
    "        actual_codes_index.append(act_icd_vector)\n",
    "\n",
    "\n",
    "        #if i%100 == 0 and i != 0:\n",
    "        #    print(i, ' sentences done.')\n",
    "\n",
    "    #Calculate Precision, Recall, F1 Score for this threshold\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(actual_codes_index, predicted_codes_index, average = 'micro')\n",
    "    specificity = calc_specificity(predicted_codes_index, actual_codes_index)\n",
    "\n",
    "    #Add to results Dataframe:\n",
    "    results = results.append({'Number of Observations': m, \n",
    "                    'Number of ICD Codes': NUM_ICD_CODES, \n",
    "                    'Threshold': thresh,\n",
    "                    'Precision': precision, \n",
    "                    'Recall': recall, \n",
    "                    'F1-Score': f1_score, \n",
    "                    'Specificity': specificity}, ignore_index=True)\n",
    "\n",
    "    print('\\nPrecision: ', precision, ' Recall: ', recall, ' F1-Score: ', f1_score, ' Specificity:', specificity)\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - start_time\n",
    "print('\\nTime elapsed: ', time_elapsed/60.0, ' minutes')    \n",
    "    \n",
    "#Print Results\n",
    "RESULT_FILENAME = 'Results/Experiment_Results_RWMS_Negation_Documentwise_' + str(DD_Data.shape[0]) + '_records_' + str(NUM_ICD_CODES) + '_codes_' + '.xlsx'\n",
    "#RESULT_FILENAME = 'Experiment_Results_NP_RWMS_Documentwise_' + str(DD_Data.shape[0]) + '_records_' + str(NUM_ICD_CODES) + '_codes_' + '.xlsx'\n",
    "results.to_excel(RESULT_FILENAME) \n",
    "print('Results Saved!')\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
